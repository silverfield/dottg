In section~\ref{sec:prel} we have defined a timetable as a set of elementary connections. While do not pose any other restrictions on this set or on the elementary connections themselves, the real world timetables usually have a specific nature. Quite often are the connections repetitive, that is, the same sequence of elementary connections is repeated in several different moments throughout the day.

Another thing we may notice is that if we talk about \textit{optimal} connections between a pair of distant cities $u$ and $v$, we are often left with a few possibilities as to \textit{which way should we go}. This is not only because the underlying graph is usually quite sparse~\footnote{Maybe with exception of the airline timetables, which tend to be more dense.}, but also because for longer distances we generally need to make use of some express connection that stops only in (small number of) bigger cities.

Thus the main idea common to the methods presented in this section: \textit{when carrying out an optimal connection between a pair of cities, one often goes along the same path regardless of the starting time}~\footnote{Or similarly, there are only few paths that are worth to follow.}. \\

\noindent To formalize this idea, we will introduce the definition of an \textit{underlying shortest path} - a path in the underlying graph that corresponds to some optimal connection in the timetable. To do this, we will first define a function $path$ that extracts the \textbf{underlying path} (trajectory in the UG) from a given connection. Let $c$ be a connection $c = (e_{1}, e_{2}, ..., e_{k})$.

\begin{equation*}
	\bm{path(c)} = shrink(from(e_{1}), from(e_{2}), ..., from(e_{k}), to(e_{k}))
\end{equation*}

\noindent Note, that if the connection involves waiting in a city (as e.g. in figure~\ref{fig:pathfunc}), $e_{x}^{i} = e_{x}^{i + 1}$ for some $i$. That is why we apply the $shrink$ function, which replaces any sub-sequences of the type $(z, z, ..., z)$ by $(z)$ in a sequence. This is rather technical way of expressing a simple intuition - for a given connection, the $path$ function outputs a sequence of visited cities. Now we can formalize the notion of underlying shortest path.

\begin{definition}
    \textbf{Underlying shortest path (USP)} \\
	A path $p = (v_{1}, v_{2}, ..., v_{k})$ in $UG_{T}$ is an \textbf{underlying shortest path} if and only if $\exists t \in \mathcal{N}: p = path(c_{(v_{1}, t, v_{k})}^{*}), c_{(v_{1}, t, v_{k})}^{*} \in C_{T}$
\end{definition}
    
\begin{figure}[h!]
	\begin{center}
		\inputTikZ{./tikzpics/pathfunc}
	\end{center}
	\caption{\label{fig:pathfunc} The $path$ function applied on a connection to get the underlying path.}
\end{figure}

\noindent Please note that the terminology might be a bit misleading - an USP is not necessarily a shortest path in the given UG. For example, the connections on a shortest path may require too much waiting and thus it might be that travelling along the paths with greater distance proofs to be faster.
	    
\subsection{\textit{USP-OR}}

	We can easily extract the underlying path from a given connection. Now let us look at this from the other way - if, for a given EA query, we know the underlying shortest path, can we reconstruct the optimal connection? One thing we could do is to blindly follow the USP and in each city take the first elementary connection to the next one on the USP. This simple method called \textit{expand} is described in algorithm~\ref{alg:expand}. 
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{expand}
		\label{alg:expand}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item path $p = (v_{1}, v_{2}, ..., v_{k})$, $v_{i} \in ct_{T}$
			\item departure time $t$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE $c$ = empty connection
			\STATE $t' = t$
			\FORALL{$i \in \{1, ..., k - 1\}$}
				\STATE $e = argmin_{e' \in C_{T}(v_{i}, v_{i + 1})} \{dep(e')|\; dep(e') \geq t'\}$ \cmt{take first available el. conn.}
				\STATE $t' = arr(e)$
				\STATE $c$ .= $e$ \cmt{add the el.conn to the resulting connection}
			\ENDFOR
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item connection $c$
		\end{itemize}
	\end{algorithm}
	\color{black}	
	
	\noindent A question is - will we get an optimal connection if we expanded all possible USPs between a pair of cities? We show that we will, provided the timetable has no \textit{overtaking}~\cite{tdroute09} of elementary connections.
	
	\begin{definition}
        \textbf{Overtaking} \\
		An elementary connection $e_{1}$ \textbf{overtakes} $e_{2}$ if, and only if $dep(e_{1}) > dep(e_{2})$ and $arr(e_{1}) < arr(e_{2})$. 
    \end{definition}
	    
    \begin{figure}[H]
	\centering
	\makebox[0pt][c]{
    \begin{minipage}{0.55\textwidth} 
    	\begin{center}
			\inputTikZ{./tikzpics/overtake}
		\end{center}
		\caption{\label{fig:overtake} An example of \textcolor{green!80!black}{\textbf{overtaking}} (in thick), depicted in a TE graph.}
	\end{minipage}
	\hspace{1cm}
	\begin{minipage}{0.35\textwidth}
		\centering
		\begin{tabular}{c|c}
		%legend
            \rowcolor{tablehead}
        	\textbf{Name} & \textbf{Overtaken} \\
        %data
			\hline
			\textit{air01} & 1\% \\
			\textit{cpsk} & 2\% \\
			\textit{gb-coach} & 1\% \\
			\textit{gb-train} & 0\% \\
			\textit{montr} & 1\% \\
			\textit{sncf} & 1\% \\
			\textit{sncf-ter} & 1\% \\
			\textit{sncf-inter} & 6\% \\
			\textit{zsr} & 0\% \\
		\end{tabular}
		\caption{\label{tab:overtake} Percentage of overtaken elementary connections in the timetables.}
	\end{minipage}
    }
	\end{figure}
    
    \begin{lemma}
    	\label{lemma:expandusp}
    	Let $T$ be a timetable without overtaking, $(x, t, y)$ an EA query in this timetable and $\bm{usps(x, y)} = \{p_{1}, p_{2}, ..., p_{k}\}$ a set of all USPs from $x$ to $y$. Define $c_{i} = $\textit{expand}$(T, p_{i}, t)$ to be the connection returned by the algorithm \textit{expand}~\ref{alg:expand}. Then $\exists j:\; c_{j} = c_{x, t, y}^{*}$.
    \end{lemma}
    \begin{proof}
    	The optimal connection $c_{x, t, y}^{*}$ has an USP $p$ which must be present in the set $usps(x, y)$, as it is the set of all USPs from $x$ to $y$. So $p = p_{j} = (v_{1}, v_{2},..., v_{l})$ from some $j$. We want to show that $c_{j}$ is the optimal connection. This may be shown inductively:
    	\begin{enumerate}
    		\item \textit{Base:} \textit{expand} reaches city $v_{1} = x$ as soon as possible (since the connection just starts there)
    		\item \textit{Induction:} \textit{expand} reached city $v_{i}$ as soon as possible, it then takes the first available el. connection to the next city $v_{i + 1}$. Since the el. connections do not overtake, \textit{expand} reached the city $v_{i + 1}$ as soon as possible.
    	\end{enumerate}
    \end{proof}
    
    \noindent We would like to stress that overtaking is understood as a situation when e.g. one train overtakes another between \textit{two subsequent stations}. This situation is not that common, however it is still present in the real world timetables~\footnote{In Slovak rails, no overtaking has been detected. This is not surprising as (to my knowledge) there are no inter-station tracks with multiple rails going in one direction. French railways, on the other hand have designated high-speed tracks and thus overtaking is not impossible.}, as shown in table~\ref{tab:overtake}. All the same, we can simply remove the overtaken elementary connections from the timetables, as they can be substituted by the quicker connection plus some waiting, thus we will not change the earliest arrival time for any query. \\
	
	\noindent The basic idea of the algorithm \textit{USP-OR} (\textbf{USP} \textbf{or}acle) is therefore simply to pre-compute all the USPs for each pair of cities. Upon a query, the algorithm expands all the USPs for a given pair of cities, reconstructs respective connections and chooses the best one. \\
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR} query}
		\label{alg:uspor-query}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item query $(x, t, y)$
		\end{itemize}
		\textbf{Pre-computed} 
		\begin{itemize}
			\item $\forall x, y: \; usps(x, y)$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE $c^{*} = null$
			\FORALL{$p \in usps(x, y)$}
				\STATE $c =$ \textit{expand}$(T, p, t)$
				\STATE $c^{*} =$ better out of $c^{*}$ and $c$
			\ENDFOR
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item connection $c$
		\end{itemize}
	\end{algorithm}
	\color{black}	
	
	\subsubsection{Analysis of \textit{USP-OR}}	
	
		\noindent We will now have a look at the four parameters of this oracle based method. As for the preprocessing time, we need to find the optimal connections from each \textit{event} in the timetable to each \textit{city} (or in other words - solve all possible OC queries). On these connections we apply the $path$ function to obtain the USPs. There is $hn$ events and one search from a single event to all cities can be done in time $\mathcal{O}(n \log n + m)$ with TD Dijkstra (in this section we use exclusively the time-dependent graphs). In worst case, $m$ could be as much as $n^{2}$ but we may bound it as $m \leq \delta_{T} n$ (where $\delta_{T}$ is the density of the timetable, defined in section \ref{sec:data}). We therefore get the \textbf{preprocessing time} $\bm{\mathcal{O}(hn^{2} (\log n + \delta))}$. 
		
		As for the preprocessed space, we need to store USPs for each pair of the cities ($n^{2}$ pairs) and each USP might be long at most $\mathcal{O}(n)$ hops. What is more, there might be multiple USPs for a single pair of cities. Therefore we have two questions with respect to the space complexity of the preprocessing:
		\begin{enumerate}
			\item What is the average size of the USPs?
			\item How many are there USPs between pairs of cities on average?
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent As for the first question, we will call the average size of USPs in a timetable $T$ the \textbf{USP diameter} and denote it $\bm{\omega_{T}}$. This value is generally higher then the OC diameter~\footnote{If, for example, we have 8 optimal connections with size 1 and 1 optimal connection with size 10, the OC diameter will be 2 but the average USP size will be 5.5.}, but can still be very well approximated by $\sqrt{n}$ (see table~\ref{tab:usp200} and plot~\ref{plot:uspdiam-cpsk}). \\
		
		\noindent To answer the second question, we will introduce the following definition:
		
		\begin{definition}
	        \textbf{USP coefficient} \\
			Given a timetable $T$ and a pair of cities $x$, $y$, we define the USP coefficient $\bm{\tau_{T}(x, y)} = |usps_{T}(x, y)|$. By $\bm{\tau_{T}}$ we will denote the average USP coefficient in timetable $T$.
	    \end{definition}
	    
	    \noindent From the table~\ref{tab:usp200} we may see that $\tau$ is quite small ($\approx 10$). Important thing however is whether or not it is constant with respect to:
		\begin{itemize}
			\item $n$ - we found $\tau$ to be slightly increasing, sometimes almost constant (see plot~\ref{plot:tau-size}) 
			\item time range - again the value of $\tau$ was slightly increasing (plot~\ref{plot:tau-trange})
		\end{itemize}
		\hspace{\fill}
		
		\noindent From the answers to our two questions we see that the \textbf{size of the preprocessed oracle} is $\bm{\mathcal{O}(\tau n^{2} \omega)}$.	    
	
		\begin{table}[H]
			\centering 
			\begin{tabular}{c|c|c|c}
			%legend
				\rowcolor{tablehead}
				\textbf{Name} & \textbf{$\bm{\tau}$} & \textbf{max $\bm{\tau(x, y)}$} & $\bm{\omega}$ \\
			%data
				\hline
				\textit{air01-200d} & 5.6 & 29 & 3.7 \\
				\textit{cpsk-200d} & 7.7 & 37 & 19.4 \\
				\textit{gb-coach-200d} & 3.5 & 29 & 7.2 \\
				\textit{gb-train-200d} & 6.8 & 40 & 10.3 \\
				\textit{montr-200d} & 2.7 & 18 & 26.1 \\
				\textit{sncf-200d} & 3.8 & 16 & 10.5 \\
				\textit{sncf-ter-200d} & 4.1 & 14 & 15.1 \\
				\textit{sncf-inter-200d} & 1.8 & 13 & 14.8 \\
				\textit{zsr-200d} & 2.3 & 13 & 16.2 \\
			\end{tabular}
			\captionof{table}{Average and maximal USP coefficients and USP diameter for daily timetables with 200 stations ($\sqrt{200} \approx 14$).}
			\label{tab:usp200}
		\end{table}	
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspdiam_cpsk}
		    \captionof{figure}{Changing of $\omega$ with increased number of stations in \textit{cpsk} dataset. Compared to the OC diameter and $\sqrt{n}$.}
		    \label{plot:uspdiam-cpsk}
		\end{minipage}
		\hspace{1cm}
		\begin{minipage}{0.45\textwidth}
			\centering
		    \inputTikZ{./tikzpics/plot_tau_size}
		    \captionof{figure}{Changing of $\tau$ with increased number of stations.}
		    \label{plot:tau-size}
		\end{minipage}
	    }
		\end{figure}
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_tau_trange}
		    \captionof{figure}{Changing of $\tau$ with increased time range.}
		    \label{plot:tau-trange}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_tauseg_trange}
		    \captionof{figure}{Changing of $\tau$ with increased time range when using segmentation.}
		    \label{plot:tauseg-trange}   
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent Also the query time depends on the USP coefficient of a given pair of cities $x$, $y$, as we have to try out all USPs in $usps(x, y)$. The expansion of a USP by \textit{expand} function takes time linear in the size of the USP~\footnote{In time-dependent graphs, this requires a constant-time retrieval of the correct interpolation point of the cost function (the piece-wise linear function that tells us the traversal time of an arc at a given time) for some time $t$. More specifically, we need to obtain an interpolation point $argmin_{(t', l)} \{t'| \; t' > t\}$. If we assume uniform distribution of departures throughout the time range of the timetable, this can be implemented in constant time. Otherwise, binary search lookup is possible in time $\mathcal{O}(\log h)$.}, leading to \textbf{query time} $\bm{\mathcal{O}(\tau \omega)}$ on average. Note, that this is pretty much optimal, as $\tau$ is basically constant and we need to output the connection itself, which takes linear time in its size.
		
		To alleviate the problem of increased $\tau$ in timetables with e.g. weekly time range, we did a simple trick called \textbf{segmentation}. First, we normally computed the USPs. Then we segmented the timetable to individual days and for each of them we stored the pointers to necessary USPs. This does not require additional memory but it makes the value of $\tau$ constant, or even decreasing (see plot~\ref{plot:tauseg-trange}) with increasing time range. Note that this would be reflected only in an improved query time of \textit{USP-OR}, the size of preprocessed data will be left unaffected. However, from this point on we assume the use of segmentation for multi-day timetables (also in \textit{USP-OR-A} algorithm, explained in the next section).
			
		Finally, the \textbf{stretch} of \textit{USP-OR} is \textbf{1}, since it returns exact answers. 
		
		\begin{table}[h!]
			\centering
			\begin{tabular}{l|c|c|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR}} & \cellcolor{oracle-clr} $\bm{prep}$ & \cellcolor{oracle-clr} $\bm{size}$ & \cellcolor{oracle-clr} $\bm{qtime}$ & \cellcolor{oracle-clr} $\bm{stretch}$ \\
			%data
				\hline
				\cellcolor{oracle-clr} \textbf{guaranteed} & $\mathcal{O}(hn^{2} (\log n + \delta))$ & $\mathcal{O}(\tau n^{2} \omega)$ & avg. $\mathcal{O}(\tau \omega)$ & $1$ \\
				\cellcolor{oracle-clr} \textbf{$\bm{\tau}$ const., $\bm{\omega \leq \sqrt{n}}$, $\bm{\delta \leq \log n}$} & $\mathcal{O}(hn^{2} \log n)$ & $\mathcal{O}(n^{2.5})$ & avg. $\mathcal{O}(\sqrt{n})$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:uspor} The summary of the \textit{USP-OR} algorithm parameters.}
		\end{table}	
	
\subsection{\textit{USP-OR-A}}
	    
	With \textit{USP-OR} the main disadvantage is its space consumption. We may decrease this space complexity by pre-computing USPs only between \textit{some} cities. The nodes that we select for this purpose will be called \textbf{access nodes} (AN for short), as for each city they would be the crucial nodes we need to pass in order to access most of the cities of $T$. It would be suitable for this access node set to have several desirable properties. In order to formulate them, we need to define a few terms first.
	
	\begin{definition}
        \textbf{Front neighbourhood} \\
		Given a timetable $T$ and access node set $\mathcal{A}$, a front neighbourhood of city $x$ is the set of all cities (including $x$) that are reachable from $x$ without the need to pass a city from $\mathcal{A}$. Formally $\bm{neigh_{\mathcal{A}}(x)} = \{y \in ct_{T}| \; \exists$ path $p = (p_{1}, p_{2}, ..., p_{k})$ from $x$ to $y$ in $ug_{T}: p_{i} \neq a \; \forall a \in \mathcal{A}, \; i \in \{2, ..., k - 1\} \}$~\footnote{In $neigh_{\mathcal{A}}(x)$ we leave out subscript identifying the timetable $T$. In situation with clear context, we may also leave out the $\mathcal{A}$ subscript.}
    \end{definition}
    
    \noindent We define analogically \textbf{back neighbourhood} (denoted $\bm{bneigh_{\mathcal{A}}(x)}$), as nodes that could be reached in UG with reversed orientation ($\overleftarrow{ug_{T}}$). Note that the access nodes that are on the boundary of $x$'s neighbourhoods are also part of these neighbourhoods. These access nodes form some sort of separator between the $x$'s neighbourhood and the rest of the graph and we will call them \textbf{local access nodes (LAN)} ($\bm{lan_{\mathcal{A}}(x)} = \mathcal{A} \cap neigh_{\mathcal{A}}(x)$), or analogically \textbf{back local access nodes} ($\bm{blan_{\mathcal{A}}(x)}$). \\
    
    \noindent Now we may formulate the three desirable properties of the access node set. Given a timetable $T$, we would like to find access node set $\mathcal{A}$ such that for some small constants $r_{1}$, $r_{2}$ and $r_{3}$:
    \begin{enumerate}
		\item The access node set is sufficiently small \\
		\begin{equation} \label{eq:r1}
			|\mathcal{A}| \leq r_{1} \cdot \sqrt{n}
		\end{equation}
		\item The average square of neighbourhood~\footnote{We required the same for back neighbourhoods.} size for cities not in $\mathcal{A}$ is at most $r_{2} \cdot n$ \\
		\begin{equation} \label{eq:r2}
			\frac{\displaystyle \sum_{x \in ct_{T} \setminus \mathcal{A}}|neigh_{\mathcal{A}}(x)|^{2}}{\displaystyle |ct_{T} \setminus \mathcal{A}|} \leq r_{2} \cdot n
		\end{equation}
		\item The average square of the number of local access nodes~\footnote{We required the same for back LANs.} for cities not in $\mathcal{A}$ is at most $r_{3}$ \\
		\begin{equation} \label{eq:r3}
			\frac{\displaystyle \sum_{x \in ct_{T} \setminus \mathcal{A}}|lan_{\mathcal{A}}(x)|^{2}}{\displaystyle |ct_{T} \setminus \mathcal{A}|} \leq r_{3}
		\end{equation}
	\end{enumerate}
	\hspace{\fill}
	
	\noindent An access node set $\mathcal{A}$ with the above mentioned properties will be called $\bm{(r_{1}, r_{2}, r_{3})}$ \textbf{access node set} (AN set). We will now explain how the \textit{USP-OR-A} (\textbf{USP} \textbf{or}acle with \textbf{a}ccess nodes) algorithm works and return to its analysis later. 
	
	During preprocessing, we need to find a good AN set and compute the USPs between every pair of access nodes. For every city $x \not \in \mathcal{A}$, we also store its $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$, $lan_{\mathcal{A}}(x)$ and $blan_{\mathcal{A}}(x)$. On a query from $x$ to $y$ at time $t$, we will first make a local search in the neighbourhood of $x$ up to $x$'s local access nodes. Subsequently, we want to find out the earliest arrival times to each of $y$'s \textit{back} local access nodes. To do this, we take advantage of the pre-computed USPs between access nodes - try out all the pairs $u \in lan(x)$ and $v \in blan(y)$ and expand the stored USPs. Finally, we make a local search from each of $y$'s back LANs to $y$, but we run the search \textit{restricted} to $y$'s back neighbourhood. For more details, see algorithms~\ref{alg:uspora-prepro} and~\ref{alg:uspora-query} and figure~\ref{fig:uspora}, where we have split the algorithm to 3 distinct phases.
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR-A} preprocessing}
		\label{alg:uspora-prepro}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE find a good AN set $\mathcal{A}$
			\STATE $\forall x, y \in \mathcal{A}$ compute $usps(x, y)$
			\STATE $\forall x \in ct_{T} \setminus \mathcal{A}$ compute $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$, $lan_{\mathcal{A}}(x)$ and $blan_{\mathcal{A}}(x)$
		\end{algorithmic}
	\end{algorithm}
	\color{black}
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR-A} query}
		\label{alg:uspora-query}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item query $(x, t, y)$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE let $lan(x) = x$ if $x \in \mathcal{A}$
			\STATE let $blan(y) = y$ if $y \in \mathcal{A}$
			\STATE \algsec{Local front search}
			\STATE perform TD Dijkstra from $x$ at time $t$ up to $lan(x)$
			\IF {$y \in neigh(x)$}
				\STATE let $c_{loc}^{*}$ be the connection to $y$ obtained by TD Dijkstra \cmt{the optimal connection may still go via ANs (though it is unlikely)}
			\ENDIF
			\STATE $\forall u \in lan(x)$ let $ea(u)$ be the arrival time and $oc(u)$ the connection to $u$ obtained by TD Dijkstra
			\STATE \algsec{Inter-AN search}
			\FORALL{$v \in blan(y)$}
				\STATE $oc(v) = null$
				\FORALL{$u \in lan(x)$}
					\FORALL{$p \in usps(u, v)$}
						\STATE $c =$ \textit{expand}$(T, p, ea(u))$
						\STATE $oc(v) =$ better out of $oc(v)$ and $c$
					\ENDFOR
				\ENDFOR
			\ENDFOR
			\STATE $\forall v \in blan(y)$ let $ea(v) = end(oc(v))$
			\STATE \algsec{Local back search}
			\FORALL{$v \in blan(y)$}
				\STATE perform TD Dijkstra from $v$ at time $ea(v)$ to $y$ restricted to $bneigh(y)$
				\STATE let $fin(v)$ be the connection returned by TD Dijkstra
			\ENDFOR
			\STATE $v^{*} = argmin_{v \in blan(y)} \{end(fin(v))\}$
			\STATE $u^{*} = from(oc(v^{*}))$
			\STATE let $c^{*} = oc(u^{*}) . oc(v^{*}) . fin(v^{*})$ \cmt{the dot ($.$) symbol is concatenation of connections}
			\STATE output better out of $c_{loc}^{*}$ and $c^{*}$
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item optimal connection $c_{(x, t, y)}^{*}$
		\end{itemize}
	\end{algorithm}
	\color{black}
	
	\begin{figure}[h!]
		\begin{center}
			\inputTikZ{./tikzpics/uspora}
		\end{center}
		\caption{\label{fig:uspora} Principle of \textit{USP-OR-A} algorithm. The arcs in \textbf{bold} mark areas that will be explored: all nodes in $neigh_{\mathcal{A}}(x)$, USPs between LANs of $x$ and back LANs of $y$ and the back neighbourhood of $y$ (possibly only part of it will be explored, since the local back search goes against the direction of the back neighbourhood).}
	\end{figure}
	
	\subsubsection{Analysis of \textit{USP-OR-A}}
	
		\noindent Let us now analyse the properties of this oracle-based method. Clearly, much depends on the way we look for the access node set. We will address this issue in next subsections but for now, we will assume we can find $(r_{1}, r_{2}, r_{3})$ AN set $\mathcal{A}$ in time $f(n)$. Then, in the preprocessing, we have to find USPs among the access nodes, which requires running Dijkstra's algorithm from each event in an access node (city from $\mathcal{A}$). There is $\mathcal{O}(r_{1}h\sqrt{n})$ such events which leads to the time complexity $\mathcal{O}(r_{1}hn^{1.5} (\log n + \delta))$. We also have to find local access nodes and neighbourhoods for each city, which can be accomplished with e.g. depth first search exploring the neighbourhood. This search algorithm (run from non-access city) has complexity linear in the number of arcs and so we could bound the total complexity as:
		
		$$
		\sum_{x \in ct_{T} \setminus \mathcal{A}} |E(neigh_{\mathcal{A}}(x))| 
		\leq \sum_{x \in ct_{T} \setminus \mathcal{A}} |neigh_{\mathcal{A}}(x)|^{2} 
		\leq r_{2} n^{2}
		$$
		
		\noindent where $E(V)$ is the set of arcs among vertices of $V$. However this is very loose upper bound, as our UGs are actually very sparse. Therefore we can improve it. We know from the equation~\ref{eq:r2} that the average square of neighbourhood size is at most $r_{2} \cdot n$. As a consequence of the Cauchy-Schwarz Inequality~\cite{cauchy} the following holds for positive real numbers $x_{i}$:
		
		$$ 
		\sqrt{\frac{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}}{n}} 
		\geq \frac{x_{1} + x_{2} + ... + x_{n}}{n} $$
		
		\noindent Applying this to our neighbourhood sizes, we get that the average size of the neighbourhood is at most $\sqrt{r_{2}n}$.  We now split the vertices of $ct_{T} \setminus \mathcal{A}$ to two categories: those with neighbourhoods of size at most $\sqrt[4]{n}$ will be part of the set $S_{\leq}$ and those with neighbourhoods of size bigger then $\sqrt[4]{n}$ will be in $S_{>}$. A neighbourhood in the first category cannot possibly contain more than $\sqrt{n}$ arcs while those in the second category can have at most $\delta_{T}|neigh_{\mathcal{A}}(x)|$ arcs (thus depending on the timetable's density).
		
		\begin{align*}
		\sum_{x \in ct_{T} \setminus \mathcal{A}} |E(neigh_{\mathcal{A}}(x))| \leq \\
		\sum_{x \in S_{\leq}} \overbrace{|E(neigh_{\mathcal{A}}(x))|}^{\leq \sqrt{n}} + 
			\sum_{x \in S_{>}} \overbrace{|E(neigh_{\mathcal{A}}(x))|}^{\leq \delta|neigh_{\mathcal{A}}(x)|} \leq \\
		n \sqrt{n} + \delta n \sqrt{r_{2}n} \leq \\
		\delta r_{2} n^{1.5}
		\end{align*}
		
		\noindent Therefore, the total \textbf{time complexity of the preprocessing} is $\mathcal{O}(f(n) + r_{1}hn^{1.5} (\log n + \delta)) + \mathcal{O}(\delta r_{2} n^{1.5}) = \bm{\mathcal{O}(f(n) + (r_{1} + r_{2}) (\delta + \log n) h n^{1.5})}$.
		
		As for the size of the preprocessed data - we need to store all the neighbourhoods, LANs and USPs between access nodes. We already know that the average size of the neighbourhood is at most $\sqrt{r_{2}n}$, thus the total size of the (front and back) neighbourhoods is $\mathcal{O}(r_{2} n^{1.5})$~\footnote{As $r_{2}$ should be a very small constant, we may disregard the square root.}. This term bounds also the size of the pre-computed local access nodes for each node.
		
		Finally we have the preprocessed USPs. There is at most $r_{1}^{2}n$ pairs of access nodes and for each of them we have possibly several USPs. We will denote by $\bm{\tau_{\mathcal{A}}}$ the average USP coefficient between pairs of cities from $\mathcal{A}$ and by $\bm{\omega_{\mathcal{A}}}$ the average USP size between cities in $\mathcal{A}$. This amounts to $\mathcal{O}(r_{1}^{2} \tau_{\mathcal{A}} \omega_{\mathcal{A}} n)$ for storage of USPs and to a total \textbf{preprocessing size} $\bm{\mathcal{O}(r_{2} n^{1.5} + r_{1}^{2} \tau_{\mathcal{A}} \omega_{\mathcal{A}} n)}$.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering 
			\begin{tabular}{c|c|c|c|c}
			%legend
				\rowcolor{tablehead}
				\textbf{Name} & $\bm{n}$ & \textbf{$\bm{\tau_{\mathcal{A}}}$} & $\bm{\omega_{\mathcal{A}}}$ & $\bm{\sqrt{n}}$ \\
			%data
				\hline
				\textit{air01-d} & 287 &  &  & 16.9 \\
				\textit{cpsk-d} & 1905 & 15.9 & 42.6 & 43.6 \\
				\textit{gb-coach-d} & 2448 &  &  & 49.5 \\
				\textit{gb-train-d} & 2555 &  &  & 50.5 \\
				\textit{montr-d} & 217 &  &  & 14.7 \\
				\textit{sncf-d} & 2646 &  &  & 51.4 \\
				\textit{sncf-ter-d} & 2637 &  &  & 51.4 \\
				\textit{sncf-inter-d} & 366 &  &  & 19.1 \\
				\textit{zsr-d} & 233 &  &  & 15.3 \\
			\end{tabular}
			\captionof{table}{USP coefficient and diameter for access node sets, daily timetables.}
			\label{tab:anusp-d}
		\end{minipage}
		\hspace{1cm}
		\begin{minipage}{0.45\textwidth}
			\centering
		    \inputTikZ{./tikzpics/plot_anuspdiam_cpsk}
		    \captionof{figure}{Changing of $\omega_{\mathcal{A}}$ with increased number of stations in \textit{cpsk} dataset. Compared to the OC diameter and $\sqrt{n}$.}
		    \label{plot:anuspdiam-cpsk}
		\end{minipage}
	    }
		\end{figure}
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}
	    	\centering
		    \inputTikZ{./tikzpics/plot_antau_size}
		    \captionof{figure}{Changing of $\tau_{\mathcal{A}}$ with increased number of stations.}
		    \label{plot:antau-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_antau_trange}
		    \captionof{figure}{Changing of $\tau_{\mathcal{A}}$ with increased time range (using segmentation).}
		    \label{plot:antau-trange}  
	    \end{minipage}
	    }
		\end{figure}		
		
		On a query from $x$ at time $t$ to $y$, we first perform the \textit{local front search} (see algorithm~\ref{alg:uspora-query}). In this step we explore the neighbourhood of $x$ with a time-dependent Dijkstra's algorithm, which takes on average time $\mathcal{O}(\sqrt{r_{2}n} (\log (\sqrt{r_{2}n}) + \delta))$. We then expand all the USPs between $u$ and $v$ such that $u \in lan(x)$ and $v \in blan(y)$, which takes on average $\mathcal{O}(r_{3} \tau_{\mathcal{A}} \omega_{\mathcal{A}})$. Finally, from each $v \in blan(y)$ we do a TD Dijkstra, restricted to $bneigh(y)$, leading to time complexity $\mathcal{O}(r_{3}\sqrt{r_{2}n} (\log (\sqrt{r_{2}n}) + \delta))$.
		
		Summing up the three terms we obtain the \textbf{query time} of $\bm{\mathcal{O}(r_{2} r_{3} \sqrt{n} (\log (r_{2}n) + \delta) + r_{3} \tau_{\mathcal{A}} \omega_{\mathcal{A}})}$.
		
		\textbf{Stretch} of the \textit{USP-OR-A} algorithm is \textbf{1}, as it is exact algorithm. \\
		
		\noindent The resulting bounds do not look very appealing. This is because we wanted to preserve the generality - the concrete bounds will depend on what kind of properties the timetables have and what algorithm for finding the AN set is plugged in. In table~\ref{tab:uspora}, we summarize the parameters of \textit{USP-OR-A} method and provide the bounds for a case when the properties of the timetables correspond to those we have measured in our datasets and when we have an algorithm that finds good AN set.
		
		\begin{table}[h!]
			\centering
			\small
			\begin{tabular}{l|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR-A}} & 
				\cellcolor{oracle-clr} \textbf{guaranteed} & 
				\cellcolor{oracle-clr} \textbf{$\bm{\tau, r_{1}, r_{2}, r_{3}}$ const., $\bm{\omega \leq \sqrt{n}}$, $\bm{\delta \leq \log n}$} \\
			%data
				\hline
				\cellcolor{oracle-clr} $\bm{prep}$ & $\mathcal{O}(f(n) + (r_{1} + r_{2}) (\delta + \log n) h n^{1.5})$ & $\mathcal{O}(f(n) + h n^{1.5} \log n)$ \\
				\cellcolor{oracle-clr} $\bm{size}$ & $\mathcal{O}(r_{2} n^{1.5} + r_{1}^{2} \tau_{\mathcal{A}} \omega_{\mathcal{A}} n)$ & $\mathcal{O}(n^{1.5})$ \\
				\cellcolor{oracle-clr} $\bm{qtime}$ & avg. $\mathcal{O}(r_{2} r_{3} \sqrt{n} (\log (r_{2}n) + \delta) + r_{3} \tau_{\mathcal{A}} \omega_{\mathcal{A}})$ & avg. $\mathcal{O}(\sqrt{n} \log n)$ \\
				\cellcolor{oracle-clr} $\bm{stretch}$ & $1$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:uspora} The summary of the \textit{USP-OR-A} algorithm parameters.}
		\end{table}
		
	\subsubsection{Correctness of \textit{USP-OR-A}}
	
		\noindent Finally, we will proof the correctness of the algorithm, i.e. that it always returns the optimal connection.
		
		\begin{theorem}
			The algorithm \textit{USP-OR-A} (\ref{alg:uspora-prepro}, \ref{alg:uspora-query}) always returns the optimal connection.
		\end{theorem}
		
		\begin{proof}
			Let $\mathcal{A}$ be the set of access nodes and consider a query from city $x$ to city $y$ at any time $t$. If $x \in \mathcal{A}$ and $y \in \mathcal{A}$, an optimum is returned due to lemma~\ref{lemma:expandusp} (in such a case, we basically run \textit{USP-OR} algorithm). \\
			
			\noindent In the following we will assume that $\bm{y \not \in neigh(x)}$, which means that the optimal connection goes through some access node $u \in lan(x)$ and $v \in blan(y)$. Note that it may be that $u = v$. \\
			
			\noindent What we would like to prove as a next step is that we reach the back LANs of $y$ (or $y$ itself if it is an access node) at the earliest arrival time. After the \textit{local front search}, we have reached the $x$'s local ANs at times $ea(u) \; \forall u \in lan(x)$. For some local access node this value is the true earliest arrival. Let us denote the set of such local ANs as $lan^{*}(x)$. The crucial thing to realize is that the optimal connection to any city out of the $x$'s neighbourhood will lead via some $u \in lan^{*}(x)$ (see figure~\ref{fig:usporaproof2}). And because the \textit{inter-AN search} phase finds \textit{optimal} connections between pairs $u \in lan(x)$ and $v \in blan(y)$, it follows that for each $v \in blan(y)$ the $ea(v)$ is the earliest arrival to this city after the \textit{inter-AN search} phase.
			
			\begin{figure}[h!]
				\begin{center}
					\inputTikZ{./tikzpics/usporaproof2}
				\end{center}
				\caption{\label{fig:usporaproof2} On the picture $lan(x) = \{G, H\}$ and $blan(y) = \{G, H, I\}$. In \textbf{thick} we have highlighted the optimal connection. The connection to $H$ is sub-optimal after the \textit{local front search} phase, however the optimal connection to $y$ (and to $H$ and $I$ as well) leads through $lan^{*}(x)$ (some of $x$'s local access nodes to which we have an optimal connection after the \textit{local front search}. Particularly, in this case it goes through $G$).}
			\end{figure}
			
			In the \textit{local back search} we run a TD Dijkstra search from all back LANs of $y$. And since this algorithm is exact and starts from each back LAN as early as possible, we get the optimal connection to $y$. \\
			
			\noindent It remains to show that if $\bm{y \in neigh(x)}$, we also get the optimal connection. In such case, we simply compare the connection that goes via access nodes and the one that was obtained solely within the neighbourhood and output the shorter one. As there are no other options, the proof is complete.
		\end{proof}
	
	\subsubsection{Modifications of \textit{USP-OR-A}}
	
		\noindent Our implementation of the \textit{USP-OR-A} algorithm uses one slight improvement, which we did not mention in its description, since it is more of an optimization technique without any theoretical guarantees on actual improvement of the running time. However, we consider it an interesting idea so we mention it at this place.
		
		\begin{definition}
	        \textbf{USP tree} \\
			Given a pair of cities $x$ and $y$ in a timetable $T$, we will call a USP tree the graph made out of edges of all USPs in $usp_{T}(x, y)$: $\bm{usp^{3}_{T}(x, y)} = (V^{3}, E^{3})$ where $V^{3} = \{v| \; v$ lays on some $p \in usp_{T}(x, y)\}$ and $E^{3} = \{(a, b)| \; (a, b)$ is part of some $p \in usp_{T}(x, y)\}$.
	    \end{definition}
	    
	    \noindent We could take advantage of these USP trees to speed up the \textit{local front search} phase of the algorithm, where we unnecessarily explore the whole neighbourhood when we could just go along the arcs of the USP trees. The picture~\ref{fig:uspora3} depicts this. \\
	    
	    \begin{figure}[h!]
			\begin{center}
				\inputTikZ{./tikzpics/uspora3}
			\end{center}
			\caption{\label{fig:uspora3} Using USP trees (\textbf{thick} non-dashed arcs in \textcolor{purple}{$\bm{neigh_{\mathcal{A}}(x)}$}) to decrease the explored area in \textit{local front search}. A full neighbourhood search is done only when $y \in neigh(x)$.}
		\end{figure}
		
		\noindent The interesting thing about this is the exploitation of both - timetable and its underlying graph. While the neighbourhood of a node is something static, related only to the structure of the UG and generally time-independent, the USP trees reflect to some extent the properties of the timetable (e.g. which ways are frequently serviced and thus provide optimal connections). By intersecting these two things, we get the area that is \textit{worth} to be explored and that is \textit{small} at the same time (provided, of course, that the neighbourhoods are small).	    
	 
\subsection{Selection of access node set}
	
	The challenge in the \textit{USP-OR-A} algorithm comes down to the selection of a good access node set - a $(r_{1}, r_{2}, r_{3})$ AN set with both three parameters as low as possible. However, intuitively (and experimentally verified), decreasing e.g. $r_{1}$ (the AN set size) increases $r_{2}$ (the size of the neighbourhoods). We therefore have to do some compromises.
	
	In the following we first show the problem of choosing an optimal access node set to be NP-hard. We then present our methods for heuristic selection of access nodes and show their performance on real data.
	    
	\subsubsection{Choosing the optimal access node set}

		A question stands - what is an optimal access node set?	To keep the query time as low as possible, we need to avoid large neighbourhood sizes, because that would mean spending too much time doing local searches. A pretty good upper bound for neighbourhood sizes seems to be $\sqrt{n}$ (i.e. $r_{1} = 1$) - the idea is that in such case the local searches cannot possibly last longer then $\mathcal{O}(n)$ while the \textit{inter-AN search} is linear in the size of the connection and can also be at most $\mathcal{O}(n)$. In practice, both of these steps will be faster because the neighbourhoods are sparse and because the connections are on average much shorter then $n$. However, it gives an idea of why $\sqrt{n}$ should be considered for a target neighbourhood size.
		
		Therefore, the question stands: What is the smallest set of ANs, such that the neighbourhood sizes are all under $\sqrt{n}$? More formally, for a timetable $T$, the task is to minimize $|\mathcal{A}|$ where $\mathcal{A} \subseteq ct_{T}$ and $\forall x \in ct_{T} \setminus \mathcal{A}: |neigh_{\mathcal{A}}(x)| \leq \sqrt{n}$. We will call this the \textbf{problem of the optimal access node set} and in what follows we will show that it is NP-complete.
		
		\begin{theorem}
			The problem of the optimal access node set is NP-complete
		\end{theorem}
		
		\begin{proof}
			We will make a reduction of the \textit{min-set cover} problem (a NP-complete problem) to the problem of optimal AN set. \\
			
			\noindent Consider an instance of the min-set cover problem:
			\begin{itemize}
				\item A universe $U = \{1, 2, ..., m\}$
				\item $k$ subsets of $U$: $S_{i} \subseteq U \; i = \{1, 2, ..., k\}$ whose union is $U$: $\bigcup\limits_{1 \leq i \leq k} S_{i} = U$
			\end{itemize}
			\hspace*{\fill}
			
			\noindent Denote $\mathcal{S} = \{S_{i}| \; 1 \leq i \leq k\}$. The task is to choose the smallest subset $\mathcal{S}^{*}$ of $\mathcal{S}$ that still covers the universe ($\bigcup\limits_{S_{i} \in \mathcal{S}^{*}} S_{i} = U$). We will now do a simple conversion (in polynomial time) of the instance of min-set cover to the instance of the optimal AN set problem (which is represented by the underlying graph of $T$).
			
			 For each $j \in U$, we will make a complete graph of $\beta_{j}$ vertices (the value of $\beta_{j}$ will be discussed later) named $m_{j}$ and for each set $S_{i}$ we make a vertex $s_{i}$ and vertex $s_{i}'$. We now connect all vertices of $m_{j}$ to $s_{i}$ for each $j \in S_{i}$. Finally, for we connect $s_{i}$ to $s_{i}'$, $1 \leq i \leq k$. \\
			 
			\noindent \textbf{Example}. Let $m = 10$ (thus $U = \{1, 2, ..., 10\}$) and $k = 13$:
			\begin{itemize}
				\item $S_{1} = \{1, 3, 10\}$
			 	\item $S_{2} = \{1, 2\}$
			 	\item ...
			 	\item $S_{13} = \{2, 3, 10\}$
			\end{itemize}
			\hspace*{\fill}
			 
			\noindent For this instance of min set-cover, we construct the graph as depicted on picture~\ref{fig:reduction}.
			 
			\begin{figure}[h!]
				\begin{center}
					\inputTikZ{./tikzpics/reduction}
				\end{center}
				\caption{\label{fig:reduction} The principle of the reduction. In $m_{i}$, there are actually complete graphs of $\beta_{i}$ vertices (as shown for $m_{1}$). \textbf{Thick} arcs represent arcs from all the vertices of respective $m_{i}$. The $s_{i}$ vertices are connected to their $s_{i}'$ versions. If e.g. $s_{1}$ is selected as an access node, $s_{1}'$ is no longer part of any neighbourhood (except for its own).}
			\end{figure}
			
			\noindent Now we would like to clarify the sizes of $m_{i}$. Define $\alpha_{i}$ to be the number of sets $S_{j}$ that contain $i$: $\alpha_{i} = |\{S_{j} \in \mathcal{S}| \; i \in S_{j}\}|$ and assume the constructed graph has $n$ vertices. We want the $\beta_{i}$ to satisfy $\beta_{i} \geq 2$ and $\beta_{i} + 2\alpha_{i} - 1 \leq \sqrt{n}$ but $\beta_{i} + 2\alpha_{i} > \sqrt{n}$. The last two inequalities would mean that if at least one $s_{j}$ connected to $m_{i}$ is chosen as an access node, the neighbourhood for nodes in $m_{i}$ will be still large at most $\sqrt{n}$, but if none of them is chosen, the neighbourhood size will be just over $\sqrt{n}$. We leave out the details of the construction at this place. 
			
			Now consider an optimal AN set which contains a vertex from within some $m_{i}$. If this is the case, \textbf{either} some $s_{j}$ to which $m_{i}$ is connected is selected as AN, \textbf{or} \textit{all} vertices from $m_{i}$ are access nodes \textbf{or} the neighbourhood is too large. Keep in mind that the local access nodes are also part of neighbourhoods, so unless we select for AN some of the $s_{j}$ that $m_{i}$ is connected to, the neighbourhood of any non-access node in $m_{i}$ will be too large. As there are at least two nodes in every $m_{i}$, it is more efficient to select some $s_{j}$ rather then select all nodes in $m_{i}$. Thus when it comes to selecting ANs \textit{it is worth to consider only vertices $s_{j}$}.
			
			From this point on, it is easy to see that it is optimal to select those $s_{j}$ that correspond to the optimal solution of min-set cover. The reason is that each of the $m_{i}$ will be connected to at least one access node $s_{j}$ and will thus have neighbourhood size at most $\sqrt{n}$, while the number of selected access nodes will be optimal. \\
			
			\noindent It remains to show how to choose values $\beta_{i}$. Due to the condition $\beta_{i} \leq \sqrt{n} - 2\alpha_{i} + 1$ we need to have sufficiently big $n$ to fulfil $\beta_{i} \geq 1$. We will accomplish this by adding dummy isolated vertices to the graph. Define function \textit{nextSquare($x$)} to output the smallest $y^{2} > x$ where $y$ is a natural number. We then compute $w = (max\{2\alpha_{i}\} + 2)^{2}$ and select the starting value of $n$ to be $n' =$ \textit{nextSquare($max\{w - 1, \; \sqrt{2k + m}\}$)}. We create the $s_{j}$ and $s_{j}'$ vertices and complete graphs $m_{i}$ containing so far only one vertex each. We connect everything according to the rules stated earlier in this proof and we create dummy vertices up to the capacity defined by $n$. Now we repeat the following:
			
			\begin{itemize}
				\item We compute $\sqrt{n}$ which is a natural number
				\item For $i$ from $1$ to $m$ we add vertices to $m_{i}$ till it does not contain $\sqrt{n} - 2\alpha_{i} + 1$ vertices. For each added vertex we delete one dummy vertex.
				\item If we run out of dummy vertices, $n =$ \textit{nextSquare($n$)}
				\item Break out of the loop if $|m_{i}| = \sqrt{n} - 2\alpha_{i} + 1 \; \forall i$
			\end{itemize}
			\hspace*{\fill}
			
			\noindent With each iteration of this little algorithm we will be forced to add one more vertex to all $m_{i}$ (since $\sqrt{n}$ increased by one), a so called \textit{inefficient increase}. At the beginning, we need to make at most $m\sqrt{n'}$ efficient increases to meet the breaking condition. And since $m$ is constant and the capacity of new dummy vertices increases linearly, after $t$ steps we create $\mathcal{O}(t^{2})$ dummy vertices that may be used for efficient increases. Therefore, the algorithm will stop after $\mathcal{O}(\sqrt{mn'})$ steps.
		\end{proof}
	
	\subsubsection{Choosing ANs based on node properties}
	
		In the previous sub-subsection, we have shown the problem of choosing the optimal AN set to be NP-hard. In this sub-subsection we perform a simple experiment of choosing for the access nodes the cities that seem to be the most important. More specifically, in the optimistic underlying graph (see section~\ref{sec:prel}) $ug_{T}^{opt}$ we were looking for cities with:
		\begin{enumerate}
			\item High \textbf{degree}. We consider the sum of in-degree and out-degree~\footnote{In-degree is the number of arcs going into the node and out-degree the number of outgoing arcs.} of the respective node $x$: $\bm{deg(x)} = deg_{in}(x) + deg_{out}(x)$.
			\item High \textbf{betweenness centrality} (BC). Betweenness centrality for a node $v$ is defined as 
			
			$$g(v) = \sum_{s \neq v \neq t} \frac{\displaystyle \sigma_{st}(v)}{\displaystyle \sigma_{st}}$$
			
			where $\sigma_{st}(v)$ is the number of shortest paths from $s$ to $t$ passing through $v$ and $\sigma_{st}$ is the total number of shortest paths from $s$ to $t$~\cite{centrality01}. We then scale the values to the range $<0, 1>$ to obtain for each city $x$ its scaled betweenness centrality $\bm{bc(x)}$.
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent We will denote by $\mathcal{A}^{deg}(k)$ the set of $k$ cities with highest $deg(x)$ value. We were interested in the smallest $k$ such that $\mathcal{A}^{deg}(k)$ is $(r_{1}, r_{2}, r_{3})$ AN set with $r_{2} \leq 1$ (the average square of neighbourhoods is at most $n$). Denote such set as $\bm{\mathcal{A}^{deg}}$ and the triplet $(r_{1}, r_{2}, r_{3})$ as $\bm{(r_{1}^{deg}, r_{2}^{deg}, r_{3}^{deg})}$~\footnote{Intuitively - $r_{1}^{deg}$ is the smallest $r_{1}$ such that $r_{1}\sqrt{n}$ highest-degree cities selected as ANs are enough to satisfy that the average square of neighbourhoods is at most $n$.}. \\
		
		\noindent We define similarly $\bm{\mathcal{A}^{bc}}$ and $\bm{r_{i}^{bc}}$. Plots~\ref{plot:hbcdeg-size} summarize the properties of access node sets obtained this way on daily datasets \textit{sncf} and \textit{cpsk}.
		
		\begin{figure}[htb]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_hbcdeg_sncf_size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_hbcdeg_cpsk_size}
	    \end{minipage}
	    }
	    \caption{\label{plot:hbcdeg-size} Parameters of the access node sets $\mathcal{A}^{deg}$ and $\mathcal{A}^{bc}$ with increasing $n$. Datasets \textit{sncf} (left) and \textit{cpsk} (right). $r_{2} \leq 1$. The occasional ``roller coaster'' bumps (for value of $r_{3}$) are due to our stopping criterion which does not consider $r_{3}$ at all.}
		\end{figure}
		
	\subsubsection{Choosing ANs heuristically - the \textit{locsep} algorithm}
	
		Clearly, selecting the cities for access nodes solely by high degree or BC value is not the best way. Probably the few nodes with highest degrees and BC will indeed be part of the AN set, as they are intuitively some sort of central hubs without which the network would not work. However, after we select these most important nodes to the AN set, we need some better measure of node's importance, or suitability to be an access node. In the following we present a simple heuristic approach run on underlying graph $ug_{T}$ of given timetable $T$ that evaluates its vertices based on how good local separators they are. 
		
		The algorithm that we call \textit{locsep} (as it looks for good local separators) will work in iterations, each of them resulting in a selection of the city with the highest score to the access node set $\mathcal{A}$~\footnote{Actually, in our implementation, we allow an occasional deselection of an already selected node with the \textit{lowest} score, to avoid having in the resulting set cities that had high score when selected but were not very useful access nodes at the end.}. We continue to select access nodes until we meet the following stopping criterion: $\mathcal{A}$ is $(r_{1}, r_{2}, r_{3})$ AN set with $r_{2} \leq 1$ (the average square of neighbourhoods is at most $n$)~\footnote{In our implementation, we perform some further adjustments of the resulting set, such as removing unnecessary access nodes and optimising for the $r_{3}$ value.}. We will denote the resulting set $\bm{\mathcal{A}^{loc}}$ and its parameters as $\bm{r_{i}^{loc}}$.
		
		The important thing that remains to be shown is how we compute the score for a particular city. The following text explains this. \\
		
		\noindent In each iteration, we first compute the neighbourhoods and back neighbourhoods (given the current access node set $\mathcal{A}$) for each city. We need this to evaluate the stopping criteria, but the information is also used in the computation of the \textbf{potential} (the score) of the cities. \\
		
		\noindent For a city $x$, we compute its potential $\bm{p_{x}}$ in the following way: we explore an area $\bm{A_{x}}$ of $\sqrt{n}$ nearest cities around $x$, ignoring branches of the search that start with an access node ($x$ is an exception to this, since we start the search from it, although $x \not \in A_{x}$ holds). We do this exploration in an underlying graph with no orientation and no weights. Next we get the front and back neighbourhoods of $x$ within $A_{x}$ ($\bm{fn(x)} = neigh(x) \cap A_{x}$, $\bm{bn(x)} = bneigh(x) \cap A_{x}$).
		
		For a set of access nodes $\mathcal{A}$, let us call a path $p$ in $ug_{T}$ \textbf{access-free} if it does not contain a node from $\mathcal{A}$. Now as long as $x$ is not in $\mathcal{A}$, we have a guarantee that for every pair $u \in bn(x)$ and $v \in fn(x)$ there is an access-free path from $u$ to $v$ within $A_{x}$. Our interest is how this will change after the selection of $x$.
				
		Consider now a node $y \in bn(x)$. We will call $\bm{sur(y)} = \max\{0, |neigh(y)| - \sqrt{n}\}$ the \textbf{surplus} of $y$'s neighbourhood, i.e., by how much we wish to reduce it so that it is at most $\sqrt{n}$. If the surplus is zero, $y$ will not add anything to the $x$'s potential. Otherwise, we run a restricted (to $A_{x}$) search from $y$ during which we explore $j$ vertices in $fn(x)$. We increase the potential of $x$ by $\min\{sur(y), |fn(x) - j|\}$ - i.e. by how much we can decrease the surplus of $y$'s neighbourhood. We do the same for all $y \in bn(x)$ and a similar thing for all $y \in fn(x)$ (we use $\overleftarrow{ug_{T}}$ instead of $ug_{T}$, $bneigh(y)$ instead of $neigh(y)$ etc...). For an illustration of potential computing, see figure~\ref{fig:locsep}. \\
		
		\begin{figure}[h!]
			\begin{center}
				\inputTikZ{./tikzpics/locsep}
			\end{center}
			\caption{\label{fig:locsep} The principle of computing potentials in \textit{locsep} algorithm. We explored an area of $\sqrt{n}$ nearest cities (in terms of hops) around $x$. Access nodes (like $z$) and cities behind them are ignored. Little \textcolor{purple}{squares} are nodes from $fn(x)$ and \textcolor{cyan}{diamonds} are part of $bn(x)$. From $y$ we run a forward search (the \textbf{thick} arcs). Nodes from the $fn(x)$ that were not explored in this search can only be reached via $x$ itself. Such nodes contribute to $x$'s potential assuming $y$ has large neighbourhood size.}
		\end{figure}

		\noindent Finally, we simply get the city $x \not \in \mathcal{A}$ with the highest potential and select it as an access node. We check the stopping criterion and in case it is not satisfied yet, we move on to next iteration. However, note that when a new node $x'$ is selected to $\mathcal{A}$, we do not have to re-compute neighbourhoods and potentials of all cities - it is only necessary for those cities that could reach/be reached access-free from $x'$ (i.e. nodes from $neigh_{\mathcal{A}}(x') \cup bneigh_{\mathcal{A}}(x')$). Algorithm~\ref{alg:locsep} provides a high-level overview of the locsep method. \\
		
		\color{algcolor}
		\begin{algorithm}[H]
			\color{inalgcolor}
			\caption{\textit{locsep}}
			\label{alg:locsep}
			\textbf{Input} 
			\begin{itemize}
				\item $ug_{T}$
			\end{itemize}
			\textbf{Algorithm}
			\begin{algorithmic}
				\STATE $\mathcal{A} = \emptyset$
				\STATE $ct' = ct_{T}$
				\WHILE{$r_{2} > 1$}
					\STATE $\forall x \in ct'$: compute $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$
					\STATE $\forall x \in ct'$: compute $p_{x}$
					\STATE $x' = argmax_{x \not \in \mathcal{A}} \{p_{x}\}$
					\STATE $\mathcal{A} = \mathcal{A} \cup \{x'\}$
					\STATE $ct' = neigh_{\mathcal{A}}(x') \cup bneigh_{\mathcal{A}}(x')$
				\ENDWHILE
				\STATE Remove unnecessary ANs
				\STATE Optimise $r_{3}$
			\end{algorithmic}
			\textbf{Output}
			\begin{itemize}
				\item AN set $\mathcal{A}^{loc}$ ($|\mathcal{A}^{loc}| = \sqrt{n} r^{loc}_{1}$)
			\end{itemize}
		\end{algorithm}
		\color{black}
		
		\noindent Now we would like to estimate the \textbf{time complexity} of locsep algorithm. As mentioned, one iteration consists of three parts:
		\begin{enumerate}
			\item Computing neighbourhoods. Unfortunately, at the beginning when $\mathcal{A} = \emptyset$, the neighbourhood sizes may be as large as $\mathcal{O}(n)$. Therefore, we may bound the complexity of this phase only as $\mathcal{O}(nm) = \mathcal{O}(\delta n^{2})$.
			\item Computing potentials. For a city $x$ we explore area of the size $\sqrt{n}$ and from each node in that area we do a restricted search. Therefore the total complexity of this step is $\mathcal{O}(n \cdot \sqrt{n} \cdot \delta \sqrt{n}) = \mathcal{O}(\delta n^{2})$.
			\item Selecting node with the highest potential. This can be done in $\mathcal{O}(n)$.
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent Adding up the individual terms, we get the complexity of one iteration to be at most $\mathcal{O}(\delta n^{2})$. As we aim for the resulting access node set of size $\mathcal{O}(\sqrt{n})$, we would get the total running time of $\bm{\mathcal{O}(\delta n^{2.5})}$. However, we remind that the algorithm is only a heuristics with no guarantees on the resulting access node set size~\footnote{The algorithm basically selects access nodes on a greedy basis. However, even that is done only heuristically, using local scope to reduce the time complexity.}.
		
		The resulting running time is still quite impractical for bigger timetables. For example, the computation on the dataset \textit{sncf} took more than an hour. This is due to the initial iterations, during which average neighbourhood is still very large (spanning almost the whole graph) and thus we have to do a lot of re-computations (potentials, neighbourhoods). We therefore embrace a simple trick: we do not start with $\mathcal{A} = \emptyset$ but with some access nodes already selected based on high degree. We chose to start with $\frac{2 \sqrt{n}}{3}$ nodes with the highest degree ($\mathcal{A}_{deg}(\frac{2 \sqrt{n}}{3})$) - enough to speed-up the computation but not influencing the resulting AN set too much. 
		
		The access node sets chosen with the \textit{locsep} algorithm had much better properties compared to those selected by the previous approaches. The evolution of the properties with increasing $n$ could be seen at plots~\ref{plot:locsep-size}. \\
		
		\begin{figure}[h!]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}
		    \centering
		    \inputTikZ{./tikzpics/plot_locsep_sncf_size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_locsep_cpsk_size}
	    \end{minipage}
	    }
	    \caption{\label{plot:locsep-size} Parameters of the access node set $\mathcal{A}^{loc}$ with increasing $n$. Datasets \textit{sncf} (left) and \textit{cpsk} (right). $r_{2} \leq 1$. An ideal situation would be constant (or non-increasing) functions.}
		\end{figure}	
		
		\begin{table}[H]
			\centering 
			\begin{tabular}{c|c|c}
			%legend
				\rowcolor{tablehead}
				\textbf{Name} & $\bm{r^{loc}_{1}}$ & $r^{loc}_{2}$ \\
			%data
				\hline
				\textit{air01-d} &  &  \\
				\textit{cpsk-d} &  &  \\
				\textit{gb-coach-d} &  &  \\
				\textit{gb-train-d} &  &  \\
				\textit{montr-d} &  &  \\
				\textit{sncf-d} &  &  \\
				\textit{sncf-ter-d} &  &  \\
				\textit{sncf-inter-d} &  &  \\
				\textit{zsr-d} &  &  \\
			\end{tabular}
			\captionof{table}{Parameters of $\mathcal{A}^{loc}$ for all of our datasets in their maximum size.}
			\label{tab:locsep}
		\end{table}					
		
		\noindent To sum up, in \textit{all} of our datasets~\footnote{Except \textit{air01}, which is a special type of timetable.}, each scaled to \textit{various} sizes, we were always able to find $(r_{1}, r_{2}, r_{3})$ access node set $\mathcal{A}$ with the \textit{locsep} algorithm, such that:
		\begin{itemize}
			\item $r_{1} \leq todo$
			\item $r_{2} \leq todo$
			\item $r_{3} \leq todo$
			\item $\mathcal{A}$ can be found in $\mathcal{O}(\delta n^{2.5})$
		\end{itemize}
		\hspace*{\fill}
		
		\noindent Therefore, when we use \textit{USP-OR-A} together with \textit{locsep} on our timetables, we achieve parameters as described in table~\ref{tab:usporalocsep}.
		
		\begin{table}[h!]
			\centering
			\begin{tabular}{l|c|c|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR-A + locsep}} & \cellcolor{oracle-clr} $\bm{prep}$ & \cellcolor{oracle-clr} $\bm{size}$ & \cellcolor{oracle-clr} $\bm{qtime}$ & \cellcolor{oracle-clr} $\bm{stretch}$ \\
			%data
				\hline
				\cellcolor{oracle-clr} \textbf{Our timetables} & $\mathcal{O}(\delta n^{2.5})$ & $\mathcal{O}(n^{1.5})$ & avg. $\mathcal{O}(\sqrt{n} \log n)$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:usporalocsep} Parameters for \textit{USP-OR-A} with \textit{locsep}.}
		\end{table}
	
\subsection{Performance and comparisons}

	\noindent In this subsection we give the results of the performance of our algorithms on our datasets. We focus on query time and space complexity of the preprocessed oracles. We have already introduced the speed-up as the ratio of average query time for the TD Dijkstra and the average query time for the given algorithm. We will have a similar measure for the size of the preprocessed data, which we compare against the amount of data needed to represent the actual timetable itself.
	
	\begin{definition}
		\textbf{Size-up ($\bm{szp(m)}$)}\\
		A size-up of an oracle based method $m$ is the ratio $\frac{\displaystyle size(TD)}{\displaystyle size(m)}$ where $size(TD)$ is the size of the memory necessary to store the time-dependent graph.
	\end{definition}

	\subsubsection{Performance of \textit{USP-OR}}
		
		Query time-wise, \textit{USP-OR} outperforms time-dependent Dijkstra's algorithm almost 80 times (on the subset of \textit{sncf-ter} dataset). However, this was at the cost of high space consumption of the method, in some cases requiring almost 400 times more memory then necessary for storage of the time-dependent graph. Therefore, we were not even able to preprocess the method for some of our bigger datasets. Table~\ref{tab:uspor-speedup} gives a good overview of achieved speed-ups and size-ups.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru}* & 700 & 14.5 & 396.7 \\
				\textit{cpza}* & 700 & 14.3 & 265.1 \\
				\textit{montr} & 217 & 8.8 & 61.1\\
				\textit{sncf}* & 1000 & 64.8 & 106.2 \\
				\textit{sncf-inter} & 366 & 27.0 & 30.3 \\
				\textit{sncf-ter}* & 1000 & 78.3 & 87.4 \\
				\textit{zsr} (daily) & 233 & 19.3 & 60.8 \\
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR} algorithm for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:uspor-speedup}
		\end{table}
	
		\noindent In both timetables from \textit{cp.sk} we obtained quite similar results. The query time of \textit{USP-OR} mildly rises with increasing $n$. This is due to two (not surprising) facts: 
		\begin{itemize}
			\item The USP coefficient gets slightly bigger with increasing $n$
			\item The OC diameter increases too with increasing $n$
		\end{itemize}
		\hspace{\fill}
		
		\noindent The speed-up was up to 15, however, at the cost of very high space complexity, which made it possible to try out only timetables of the size up to 700. With the \textit{montr} dataset we got similar results, but on a smaller scale.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_cpru_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{cpru}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-cpru-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-cpza-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_montr_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{montr}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-montr-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspors-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent In the datasets from SNCF, an interesting thing was that the the query-time actually decreased with increased size. This was due to the average USP coefficient getting smaller in bigger datasets while OC diameter not increasing too much. We measured here the speed-ups of up to 80 for \textit{sncf-ter}, with smaller size-ups then in case of \textit{cp.sk} timetables.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_sncfinter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf-inter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncfinter-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_sncfter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf-ter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncfter-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspors-sncf-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent On the \textit{zsr} dataset we measured how increased time range influences the query time. You may see that for both algorithms the query time almost stops increasing at some point - this is because (informally) adding time range no longer brings along new optimal connections (or underlying shortest paths in case of \textit{USP-OR}).
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_zsr_trange}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspor-zsr-trange}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_zsr_trange}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspors-zsr-trange} 
	    \end{minipage}
	    }
		\end{figure}

	\subsubsection{\textit{USP-OR-A} with \textit{locsep}}
	
		\noindent With \textit{USP-OR-A}, the speed-ups were no longer so high as in case of \textit{USP-OR-A}, but neither were the size-ups, so we could fully try out all of our datasets. The maximum speed-up was achieved in \textit{sncf-ter}, where the \textit{USP-OR-A} outperformed \textit{TD Dijkstra} almost 7 times. In our datasets, the preprocessed oracle of \textit{USP-OR-A} did not need more than 3 times the size of the TD graph. Table~\ref{tab:uspora-speedup} provides an overview of achieved speed-ups and size-ups.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru} & 871 & 1.8 & 2.97 \\
				\textit{cpza} & 1108 & 1.9 & 2.52 \\
				\textit{montr} & 217 & 1.6 & 1.14 \\
				\textit{sncf} & 2646 & 6.3 & 3.0 \\
				\textit{sncf-inter} & 366 & 3.9 & 1.59 \\
				\textit{sncf-ter} & 2637 & 6.9 & 2.43 \\
				\textit{zsr} (daily) & 233 & 2.5 & 1.99 \\	
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR-A} with \textit{locsep} for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:uspora-speedup}
		\end{table}
	
		\noindent The bus timetables proved to be a bigger challenge for \textit{USP-OR-A}, achieving milder speed-ups and requiring more memory then railways timetables. However, bigger timetables would be necessary to obtain more relevant results.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_cpru_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{cpru}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-cpru-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-cpza-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_montr_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{montr}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-montr-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{locsep} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporas-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent In our biggest datasets, we achieved the best speed-ups while the size-up still stayed relatively small (though here we better see its tendency to increase as $n^{1.5}$). It would be interesting to try out even bigger datasets as the speed-up was gradually increasing with increasing $n$.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_sncfinter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{sncf-inter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncfinter-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_sncfter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{sncf-ter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncfter-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{locsep} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}   
		    \label{plot:usporas-sncf-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent Finally, on the \textit{zsr} timetable, we see two things:
		\begin{itemize}
			\item The space-complexity of \textit{USP-OR-A} is left pretty much unaffected with increased time range.
			\item The speed-up decreases (since with increased time range, there are generally more USPs between pairs of cities which we have to try out during the query)
		\end{itemize}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_zsr_trange}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep} compared to TD Dijkstra on the \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspora-zsr-trange}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_zsr_trange}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{locsep} vs. size of TD graph on \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:usporas-zsr-trange}
	    \end{minipage}
	    }
		\end{figure}
	
	\subsubsection{\textit{USP-OR-A} with \textit{locsep Max}}
	
		\noindent We also tried out \textit{USP-OR-A} with \textit{locsep Max} to see if the difference in the stopping criterion of \textit{locsep} would influence the query times. It did help, but the difference in the performance is minimal, therefore we list only the table summarizing the speed-ups and size-ups (\ref{tab:usporam-speedup}) and the details for datasets \textit{cpza} and \textit{sncf}.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru} & 871 & 2.1 & 4.5 \\
				\textit{cpza} & 1108 & 2.1 & 3.1 \\
				\textit{montr} & 217 & 2.1 & 1.9 \\
				\textit{sncf} & 2646 & 6.6 & 3.0 \\
				\textit{sncf-inter} & 366 & 4.3 & 1.6 \\
				\textit{sncf-ter} & 2637 & 7.1 & 2.43 \\
				\textit{zsr} (daily) & 233 & 2.3 & 1.94 \\	
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR-A} with \textit{locsep Max} for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:usporam-speedup}
		\end{table}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_usporam_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep Max} compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporam-cpza-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporams_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{locsep Max} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporams-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporam_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{locsep Max} compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporam-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporams_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{locsep Max} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}   
		    \label{plot:usporams-sncf-size}
	    \end{minipage}
	    }
		\end{figure}
