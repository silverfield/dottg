In section~\ref{sec:prel} we have defined a timetable as a set of elementary connections. While do not pose any other restrictions on this set or on the elementary connections themselves, the real world timetables usually have a specific nature. Quite often are the connections repetitive, that is, the same sequence of elementary connections is repeated in several different moments throughout the day.

Another thing we may notice is that if we talk about \textit{optimal} connections between a pair of distant cities $u$ and $v$, we are often left with a few possibilities as to \textit{which way should we go}. This is not only because the underlying graph is usually quite sparse~\footnote{Maybe with exception of the airline timetables, which tend to be more dense.}, but also because for longer distances we generally need to make use of some express connection that stops only in (small number of) bigger cities.

Thus the main idea which will repeat often throughout this section: \textit{when carrying out an optimal connection between a pair of cities, one often goes along the same path regardless of the starting time}. \\

\noindent To formalize this idea, we will introduce the definition of an \textit{underlying shortest path} - a path in UG that corresponds to some optimal connection in the timetable. To do this, we will first define a function $path$ that extracts the \textbf{underlying path} (trajectory in the UG) from a given connection. Let $c$ be a connection $c = (e_{1}, e_{2}, ..., e_{k})$.

\begin{equation*}
	\bm{path(c)} = shrink(from(e_{1}), from(e_{2}), ..., from(e_{k}), to(e_{k}))
\end{equation*}

\noindent Note, that if the connection involves waiting in a city (as e.g. in picture~\ref{fig:pathfunc}), $e_{x}^{i} = e_{x}^{i + 1}$ for some $i$. That is why we apply the $shrink$ function, which replaces any sub-sequences of the type $(z, z, ..., z)$ by $(z)$ in a sequence. This was rather technical way of expressing a simple intuition - for a given connection, the $path$ function simply outputs a sequence of visited cities. Now we can formalize the underlying shortest path.

\begin{definition}
    \textbf{Underlying shortest path (USP)} \\
	A path $p = (v_{1}, v_{2}, ..., v_{k})$ in $UG_{T}$ is an \textbf{underlying shortest path} if and only if $\exists t \in \mathcal{N}: p = path(c_{(v_{1}, t, v_{k})}^{*}), c_{(v_{1}, t, v_{k})}^{*} \in C_{T}$
\end{definition}
    
\begin{figure}[h!]
	\begin{center}
		\inputTikZ{./tikzpics/pathfunc}
	\end{center}
	\caption{\label{fig:pathfunc} The $path$ function applied on a connection to get the underlying path.}
\end{figure}

\noindent Please note that the terminology might be a bit misleading - an USP is not necessarily a shortest path in the given UG. Connections on a shortest path may simple require too much waiting (the el. connections simply do not follow well enough one another) and thus it might be that travelling along the paths with greater distance proof to be faster options.
	    
\subsection{\textit{USP-OR}}

	We can easily extract the underlying path from a given connection. Now let us look at this from the other way - if, for a given EA query, we know the underlying shortest path, can we reconstruct the optimal connection? One thing we could do is to blindly follow the USP and at each stop take the first elementary connection to the next stop on the USP. This simple algorithm called \textit{Expand} is described in algorithm~\ref{alg:expand}. 
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{Expand}
		\label{alg:expand}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item path $p = (v_{1}, v_{2}, ..., v_{k})$, $v_{i} \in ct_{T}$
			\item departure time $t$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE $c$ = empty connection
			\STATE $t' = t$
			\FORALL{$i \in \{1, ..., k - 1\}$}
				\STATE $e = argmin_{e' \in C_{T}(v_{i}, v_{i + 1})} \{dep(e')|\; dep(e') \geq t'\}$ \cmt{take first available el. conn.}
				\STATE $t' = arr(e)$
				\STATE $c$ .= $e$ \cmt{add the el.conn to the resulting connection}
			\ENDFOR
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item connection $c$
		\end{itemize}
	\end{algorithm}
	\color{black}	
	
	\noindent Will we get an optimal connection if we expanded all possible USPs between a pair of cities? We show that we will, provided the timetable has no \textit{overtaking}~\cite{timetablemodelsalgs07}~\cite{tdroute09} of elementary connections.
	
	\begin{definition}
        \textbf{Overtaking} \\
		An elementary connection $e_{1}$ \textbf{overtakes} $e_{2}$ if, and only if $dep(e_{1}) > dep(e_{2})$ and $arr(e_{1}) < arr(e_{2})$. 
    \end{definition}
    
    \begin{figure}[h!]
		\begin{center}
			\inputTikZ{./tikzpics/overtake}
		\end{center}
		\caption{\label{fig:overtake} An example of \textcolor{green!80!black}{\textbf{overtaking}} (in thick), depicted in a TE graph.}
	\end{figure}
    
    \begin{lemma}
    	\label{lemma:expandusp}
    	Let $T$ be a timetable without overtaking, $(x, t, y)$ an EA query in this timetable and $\mathcal{P} = \{p_{1}, p_{2}, ..., p_{k}\}$ a set of all USPs from $x$ to $y$. Define $c_{i} = Expand(T, p_{i}, t)$ to be the connection returned by the algorithm Expand~\ref{alg:expand}. Then $\exists j:\; c_{j} = c_{x, t, y}^{*}$.
    \end{lemma}
    \begin{proof}
    	The optimal connection $c_{x, t, y}^{*}$ has an USP $p$ which must be present in the set $\mathcal{P}$, as it is the set of all USPs from $x$ to $y$. So $p = p_{j} = (v_{1}, v_{2},..., v_{l})$ from some $j$. We want to show that $c_{j}$ is the optimal connection. This may be shown inductively:
    	\begin{enumerate}
    		\item \textit{Base:} Expand reaches city $v_{1} = x$ as soon as possible (since the connection just starts there)
    		\item \textit{Induction:} Expand reached city $v_{i}$ as soon as possible, it then takes the first available el. connection to the next city $v_{i + 1}$. Since the el. connections do not overtake, Expand reached the city $v_{i + 1}$ as soon as possible.
    	\end{enumerate}
    \end{proof}
    
    \noindent We would like to stress that overtaking is understood as a situation when one carrier overtakes another between \textit{two subsequent stations}. This situation is not that common, however it is still present in the real world timetables~\footnote{In Slovak rails, no overtaking has been detected. This is not surprising as (to my knowledge) there are no inter-station tracks with multiple rails going in one direction. French railways, on the other hand have designated high-speed tracks and thus overtaking is not impossible.}, as shown in table~\ref{tab:overtake}. All the same, we can simply remove the overtaken el. connections from the timetables, as they can be substituted by the quicker connection plus some waiting. \\
    
    \begin{table}[h!]
    	\centering
		\begin{tabular}{c|c}
		%legend
            \rowcolor{tablehead}
        	\textbf{Name} & \textbf{Overtaken edges (\%)} \\
        %data
			\hline
			\textit{air01} & 1\% \\
			\textit{cpsk} &  \\
			\textit{gb-coach} &  \\
			\textit{gb-train} &  \\
			\textit{montr} & 1\% \\
			\textit{sncf} & 2\% \\
			\textit{sncf-ter} & 2\% \\
			\textit{sncf-inter} & 8\% \\
			\textit{zsr} & 0\% \\
		\end{tabular}
		\caption{\label{tab:overtake} Presence of overtaking in the timetables.}
	\end{table}
	
	\noindent The basic idea of the algorithm \textit{USP-OR} (a short-cut for USP oracle) is therefore simply to pre-compute all the USPs for each pair of cities. Upon a query, the algorithm simply expands all the USPs for a given pair of cities, reconstructs respective connections and chooses the best one. \\
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR} query}
		\label{alg:uspor-query}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item OC query $(x, t, y)$
		\end{itemize}
		\textbf{Pre-computed} 
		\begin{itemize}
			\item $\forall x, y:$ set of USPs between $x$ and $y$ ($usps(x, y)$)
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE $c^{*} = null$
			\FORALL{$p \in usps_{x, y}$}
				\STATE $c =$ \textit{Expand}$(T, p, t)$
				\STATE $c^{*} =$ better out of $c^{*}$ and $c$
			\ENDFOR
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item connection $c$
		\end{itemize}
	\end{algorithm}
	\color{black}	
	
	\subsubsection{Analysis of \textit{USP-OR}}	
	
		\noindent We will now have a look at the four parameters of this oracle based method. As for the preprocessing time, we need to find optimal connections from each \textit{event} in the timetable to each \textit{city} (or in other words - solve all possible OC queries). On these connections we apply the $path$ function to obtain the USPs. The maximum number of events in one city is the height $h$ and there is $n$ cities, thus $hn$ is the upper bound on the number of events. One search from a single event to all cities can be done in time $\mathcal{O}(n \log n + m)$ with a TD Dijkstra's algorithm run on the time-dependent graph of our timetable ($TD_{T}$). In worst case, $m$ could be as much as $n^{2}$ but we may bound it as $m \leq \delta_{T} n$ (where $\delta_{T}$ is the sparsity of the timetable, defined in section \ref{sec:data}). We therefore get the \textbf{preprocessing time} $\bm{\mathcal{O}(hn^{2} (\log n + \delta))}$. 
		
		As for the preprocessed space, we need to store USPs for each pair of the cities ($n^{2}$ pairs) and each USP might be long at most $\mathcal{O}(n)$ hops. What is more, there might be many USPs for a single pair of cities. Therefore we have two questions with respect to the space complexity of the preprocessing:
		\begin{enumerate}
			\item What is the average size of the USPs?
			\item How many are there USPs between a single pair of cities?
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent The answer for the first question is that the average USP size is equal to the OC radius of the timetable ($\gamma_{T}$) defined in section~\ref{sec:data}, which generally varies around $\sqrt{n}$ (see table~\ref{tab:tt_ocradius}). 
		
		\noindent To answer the second question, we will introduce the following definition:
		
		\begin{definition}
	        \textbf{USP coefficient} \\
			Given a timetable $T$ and a pair of cities $x$, $y$, the USP coefficient $\bm{\tau_{T}(x, y)} = |usps_{T}(x, y)|$, where $\bm{usps_{T}(x, y)}$ is the set of USPs between $x$ and $y$. By $\bm{\tau_{T}}$ we will denote the average USP coefficient in timetable $T$.
	    \end{definition}
	    
	    \noindent From the table~\ref{tab:usp200} we can see, that there are not many USPs on average, meaning that $\tau$ is usually some small number. Also, we see that it slightly increases with increasing time range (plot~\ref{plot:usp-air-timerange}), but not with increasing $n$, the size of the timetable (plot~\ref{plot:usp-sncf-size}). Thus we can consider $\tau$ to be bound by a small constant when it comes to daily timetables. 
	    
	    From the answers to our two questions we see that the \textbf{size of the preprocessed oracle} is $\bm{\mathcal{O}(\tau n^{2} \gamma)}$.
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering 
			\begin{tabular}{c|c|c}
			%legend
				\rowcolor{tablehead}
				\textbf{Name} & \textbf{$\tau$} & \textbf{max $\tau(x, y)$} \\
			%data
				\hline
				\textit{air01-d} &  \\
				\textit{cpsk-d} &  \\
				\textit{gb-coach-d} &  \\
				\textit{gb-train-d} &  \\
				\textit{montr-d} &  \\
				\textit{sncf-d} &  \\
				\textit{sncf-ter-d} &  \\
				\textit{sncf-inter-d} &  \\
				\textit{zsr-d} &  \\
			\end{tabular}
			\captionof{table}{Average and maximal USP coefficients for daily timetables.}
			\label{tab:usp200}
		\end{minipage}
		\hspace{1cm}
		\begin{minipage}{0.45\textwidth}
			\centering
		    \inputTikZ{./tikzpics/plot_tau_sncf_size}
		    \captionof{figure}{Changing of $\tau$ with increased number of stations in \textit{sncf} dataset.}
		    \label{plot:usp-sncf-size} 
		\end{minipage}
	    }
		\end{figure}
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_tau_cpsk_size}
		    \captionof{figure}{Changing of $\tau$ with increased number of stations in \textit{cpsk} dataset.}
		    \label{plot:usp-cpsk-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_tau_gbcoach_size}
		    \captionof{figure}{Changing of $\tau$ with increased number of stations in \textit{gb-coach} dataset.}
		    \label{plot:usp-gbcoach-size}   
	    \end{minipage}
	    }
		\end{figure}	
	
	    \begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_tau_air01_timerange}
		    \captionof{figure}{Changing of $\tau$ with increased time range in \textit{air01} dataset. 1 day = about 800 in height.}
		    \label{plot:usp-air-timerange}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_tau_zsr_timerange}
		    \captionof{figure}{Changing of $\tau$ with increased time range in \textit{zsr} dataset. 1 day = about  in height.}
		    \label{plot:usp-zsr-timerange}   
	    \end{minipage}
	    }
		\end{figure}
		
		The query time also depends on the USP coefficient of a given pair of cities $x$, $y$, as we have to try out all USPs in $usps(x, y)$. The expansion of a USP by \textit{Expand} function takes time linear in the size of the USP~\footnote{In time-dependent graphs, this requires a constant-time retrieval of the correct interpolation point of the cost function (the piece-wise linear function that tells us the traversal time of an arc at a given time) for some time $t$. More specifically, we need to obtain an interpolation point $argmin_{(t', l)} \{t'| \; t' > t\}$. If we assume uniform distribution of departures throughout the time range of the timetable, this can be implemented in constant time. Otherwise, binary search lookup is possible in time $\mathcal{O}(\log h)$.}, leading to \textbf{query time} $\bm{\mathcal{O}(\tau \gamma)}$ on average. Note, that this is pretty much optimal, as $\tau$ is basically constant and we need to output the connection itself, which takes linear time in its size.
			
		Finally, the \textbf{stretch} of \textit{USP-OR} is \textbf{1}, as it returns exact answers. 
		
		\begin{table}[h!]
			\centering
			\begin{tabular}{l|c|c|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR}} & \cellcolor{oracle-clr} $\bm{prep}$ & \cellcolor{oracle-clr} $\bm{size}$ & \cellcolor{oracle-clr} $\bm{qtime}$ & \cellcolor{oracle-clr} $\bm{stretch}$ \\
			%data
				\hline
				\cellcolor{oracle-clr} \textbf{guaranteed} & $\mathcal{O}(hn^{2} (\log n + \delta))$ & $\mathcal{O}(\tau n^{2} \gamma)$ & avg. $\mathcal{O}(\tau \gamma)$ & $1$ \\
				\cellcolor{oracle-clr} \textbf{$\bm{\tau}$ const., $\bm{\gamma \leq \sqrt{n}}$, $\bm{\delta \leq \log n}$} & $\mathcal{O}(hn^{2} \log n)$ & $\mathcal{O}(n^{2.5})$ & avg. $\mathcal{O}(\sqrt{n})$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:uspor} The summary of the \textit{USP-OR} algorithm parameters. The second row corresponds e.g. to the \textit{sncf} dataset.}
		\end{table}	
	
\subsection{\textit{USP-OR-A}}
	    
	With \textit{USP-OR} the main disadvantage is its space consumption. We may decrease this space complexity by pre-computing USPs only among \textit{some} cities. The nodes that we select for this purpose will be called \textbf{access nodes} (AN for short), as for each city they would be the crucial nodes we need to pass in order to access most of the cities of $T$. It would be suitable for this access node set to have several desirable properties. In order to formulate them, we need to define a few terms first.
	
	\begin{definition}
        \textbf{Front neighbourhood} \\
		Given a timetable $T$ and access node set $\mathcal{A}$, a front neighbourhood of city $x$ are all cities (including $x$) that are reachable from $x$ \textit{not} via $\mathcal{A}$. Formally $\bm{neigh_{\mathcal{A}}(x)} = \{y| \; \exists$ path $p = (p_{1}, p_{2}, ..., p_{k})$ from $x$ to $y$ in $ug_{T}: p_{i} \neq a \; \forall a \in \mathcal{A}, \; i \in \{2, ..., k - 1\} \}$~\footnote{We leave out subscript identifying the timetable $T$. In situation with clear context, we may also leave out the $\mathcal{A}$ subscript.}
    \end{definition}
    
    \noindent We define analogically \textbf{back neighbourhood} (denoted $\bm{bneigh_{\mathcal{A}}(x)}$), as nodes that could be reached in reversed UG ($\overleftarrow{ug_{T}}$). Note that the access nodes that are on the boundary of $x$'s neighbourhoods are also part of these neighbourhoods. These access nodes form some sort of separator between the $x$'s neighbourhood and the rest of the graph and we will call them \textbf{local access nodes (LAN)} ($\bm{lan_{\mathcal{A}}(x)} = \mathcal{A} \cap neigh_{\mathcal{A}}(x)$), or analogically \textbf{back local access nodes} ($\bm{blan_{\mathcal{A}}(x)}$). \\
    
    \noindent Now we may formulate the three desired properties of the access node set $\mathcal{A}$. Given a timetable $T$ and small constants $r_{1}$, $r_{2}$ and $r_{3}$, we would like to find access node set $\mathcal{A}$ such that:
    \begin{enumerate}
		\item The access node set is sufficiently small \\
		\begin{equation} \label{eq:r1}
			|\mathcal{A}| \leq r_{1} \cdot \sqrt{n}
		\end{equation}
		\item The average square of neighbourhood~\footnote{We required the same for back neighbourhoods.} size for cities not in $\mathcal{A}$ is at most $r_{2} \cdot n$ \\
		\begin{equation} \label{eq:r2}
			\frac{\displaystyle \sum_{x \in ct_{T} \setminus \mathcal{A}}|neigh_{\mathcal{A}}(x)|^{2}}{\displaystyle |ct_{T} \setminus \mathcal{A}|} \leq r_{2} \cdot n
		\end{equation}
		\item The average square of the number of local access nodes~\footnote{We required the same for back LANs.} for cities not in $\mathcal{A}$ is at most $r_{3}$ \\
		\begin{equation} \label{eq:r3}
			\frac{\displaystyle \sum_{x \in ct_{T} \setminus \mathcal{A}}|lan_{\mathcal{A}}(x)|^{2}}{\displaystyle |ct_{T} \setminus \mathcal{A}|} \leq r_{3}
		\end{equation}
	\end{enumerate}
	\hspace{\fill}
	
	\noindent An access node set $\mathcal{A}$ with the above mentioned properties will be called $\bm{(r_{1}, r_{2}, r_{3})}$ \textbf{access node set} (AN set). We will now explain how the \textit{USP-OR-A} (\textit{USP-OR} with access nodes) algorithm works and return to its analysis later. 
	
	During preprocessing, we need to find a good AN set and compute the USPs between every pair of access nodes. For every city $x \not \in \mathcal{A}$, we also store its $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$, $lan_{\mathcal{A}}(x)$ and $blan_{\mathcal{A}}(x)$. On a query from $x$ to $y$ at time $t$, we will first make a local search in the neighbourhood of $x$ up to $x$'s local access nodes. Subsequently, we want to find out the earliest arrival times to each of $y$'s \textit{back} local access nodes. To do this, we take advantage of the pre-computed USPs between access nodes - try out all the pairs $u \in lan(x)$ and $v \in blan(y)$ and expand the stored USPs. Finally, we make a local search from each of $y$'s back LANs to $y$, but we run the search \textit{restricted} to $y$'s back neighbourhood. For more details, see algorithms~\ref{alg:uspora-prepro} and~\ref{alg:uspora-query} and picture~\ref{fig:uspora}, where we have split the algorithms to 3 distinct phases.
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR-A} preprocessing}
		\label{alg:uspora-prepro}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE find a good AN set $\mathcal{A}$
			\STATE $\forall x, y \in \mathcal{A}$ compute $usps(x, y)$
			\STATE $\forall x \in ct_{T} \setminus \mathcal{A}$ compute $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$, $lan_{\mathcal{A}}(x)$ and $blan_{\mathcal{A}}(x)$
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item output everything we have computed
		\end{itemize}
	\end{algorithm}
	\color{black}
	
	\color{algcolor}
	\begin{algorithm}[H]
		\color{inalgcolor}
		\caption{\textit{USP-OR-A} query}
		\label{alg:uspora-query}
		\textbf{Input} 
		\begin{itemize}
			\item timetable $T$
			\item OC query $(x, t, y)$
		\end{itemize}
		\textbf{Algorithm}
		\begin{algorithmic}
			\STATE let $lan(x) = x$ if $x \in \mathcal{A}$
			\STATE let $blan(y) = y$ if $y \in \mathcal{A}$
			\STATE \algsec{Local front search}
			\STATE perform TD Dijkstra from $x$ at time $t$ up to $lan(x)$
			\IF {$y \in neigh(x)$}
				\STATE let $c_{loc}^{*}$ be the connection to $y$ obtained by TD Dijkstra \cmt{the optimal connection may still go via ANs (though it is unlikely)}
			\ENDIF
			\STATE $\forall u \in lan(x)$ let $ea(u)$ be the arrival time and $oc(u)$ the conn. to $u$ obtained by TD Dijkstra
			\STATE \algsec{Inter-AN search}
			\FORALL{$v \in blan(y)$}
				\STATE $oc(v) = null$
				\FORALL{$u \in lan(x)$}
					\FORALL{$p \in usps(u, v)$}
						\STATE $c =$ \textit{Expand}$(T, p, ea(u))$
						\STATE $oc(v) =$ better out of $oc(v)$ and $c$
					\ENDFOR
				\ENDFOR
			\ENDFOR
			\STATE $\forall v \in blan(y)$ let $ea(v) = end(oc(v))$
			\STATE \algsec{Local back search}
			\FORALL{$v \in blan(y)$}
				\STATE perform TD Dijkstra from $v$ at time $ea(v)$ to $y$ restricted to $bneigh(y)$
				\STATE let $fin(v)$ be the connection returned by TD Dijkstra
			\ENDFOR
			\STATE $v^{*} = argmin_{v \in blan(y)} \{end(fin(v))\}$
			\STATE $u^{*} = from(oc(v^{*}))$
			\STATE let $c^{*} = oc(u^{*}) . oc(v^{*}) . fin(v^{*})$ \cmt{the dot ($.$) symbol is concatenation of connections}
			\STATE output better out of $c_{loc}^{*}$ and $c^{*}$
		\end{algorithmic}
		\textbf{Output}
		\begin{itemize}
			\item optimal connection $c_{(x, t, y)}^{*}$
		\end{itemize}
	\end{algorithm}
	\color{black}
	
	\begin{figure}[h!]
		\begin{center}
			\inputTikZ{./tikzpics/uspora}
		\end{center}
		\caption{\label{fig:uspora} Principle of \textit{USP-OR-A} algorithm. The arcs in \textbf{bold} mark areas that will be explored: all nodes in $neigh_{\mathcal{A}}(x)$, USPs between LANs of $x$ and back LANs of $y$ and the back neighbourhood of $y$ (possibly only part of it will be explored, since the local back search goes against the direction in which the back neighbourhood was created).}
	\end{figure}
	
	\subsubsection{Analysis of \textit{USP-OR-A}}
	
		\noindent Let us now analyse the properties of this oracle-based method. Clearly, much depends on the way we look for the access node set. We will address this issue in next subsections but for now, we will assume we can find $(r_{1}, r_{2}, r_{3})$ AN set $\mathcal{A}$ in time $f(n)$. Then, in the preprocessing, we have to find USPs among the access nodes, which requires running Dijkstra's algorithm from each event in a city from $\mathcal{A}$. There is $\mathcal{O}(r_{1}h\sqrt{n})$ such events which leads to the time complexity $\mathcal{O}(r_{1}hn^{1.5} (\log n + \delta))$. We also have to find local access nodes and neighbourhoods for each city, which can be accomplished with e.g. depth first search exploring the neighbourhood. This search algorithm (run from non-access city) has complexity linear in the number of arcs and so we could bound the total complexity as:
		
		$$
		\sum_{x \in ct_{T} \setminus \mathcal{A}} |E(neigh_{\mathcal{A}}(x))| 
		\leq \sum_{x \in ct_{T} \setminus \mathcal{A}} |neigh_{\mathcal{A}}(x)|^{2} 
		\leq r_{2} n^{2}
		$$
		
		\noindent where $E(V)$ is the set of arcs among vertices of $V$. However this is very loose upper bound, as our UGs are actually very sparse. Therefore we can improve it. We know from the equation~\ref{eq:r2} that the average square of neighbourhood size is $\leq r_{2} \cdot n$. As a consequence of the Cauchy-Schwarz Inequality~\cite{cauchy} the following holds for positive real numbers $x_{i}$:
		
		$$ 
		\sqrt{\frac{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}}{n}} 
		\geq \frac{x_{1} + x_{2} + ... + x_{n}}{n} $$
		
		\noindent Applying this to our neighbourhood sizes, we get that the average size of the neighbourhood is at most $\sqrt{r_{2}n}$.  We now split the vertices of $ct_{T} \setminus \mathcal{A}$ to two categories: those with neighbourhoods of size $\leq \sqrt[4]{n}$ will be part of the set $S_{\leq}$ and those with neighbourhoods of size bigger then $\sqrt[4]{n}$ will be in $S_{>}$. A neighbourhood in the first category cannot possibly contain more than $\sqrt{n}$ arcs while those in the second category can have at most $\delta_{T}|neigh_{\mathcal{A}}(x)|$ arcs, depending on the timetable's density.
		
		\begin{align*}
		\sum_{x \in ct_{T} \setminus \mathcal{A}} |E(neigh_{\mathcal{A}}(x))| \leq \\
		\sum_{x \in S_{\leq}} \overbrace{|E(neigh_{\mathcal{A}}(x))|}^{\leq \sqrt{n}} + 
			\sum_{x \in S_{>}} \overbrace{|E(neigh_{\mathcal{A}}(x))|}^{\leq \delta|neigh_{\mathcal{A}}(x)|} \leq \\
		n \sqrt{n} + \delta n \sqrt{r_{2}n} \leq \\
		\delta r_{2} n^{1.5}
		\end{align*}
		
		\noindent Therefore, the total \textbf{time complexity of the preprocessing} is $\mathcal{O}(f(n) + r_{1}hn^{1.5} (\log n + \delta)) + \mathcal{O}(\delta r_{2} n^{1.5}) = \bm{\mathcal{O}(f(n) + (r_{1} + r_{2}) (\delta + \log n) h n^{1.5})}$.
		
		As for the size of the preprocessed data - we need to store all the neighbourhoods, LANs and USPs between access nodes. We already know that the average size of the neighbourhood is $\leq \sqrt{r_{2}n}$, thus the total size of the (front and back) neighbourhoods is $\mathcal{O}(r_{2} n^{1.5})$~\footnote{As $r_{2}$ will be a very small constant, we may disregard the square root.}. This term bounds also the size of the pre-computed local access nodes for each node.
		
		Finally we have the preprocessed USPs. There is at most $r_{1}^{2}n$ pairs of access nodes and for each of them we have possibly several USPs. We will denote by $\bm{\tau_{\mathcal{A}}}$ the average USP coefficient between pairs of cities from $\mathcal{A}$ and by $\bm{\gamma_{\mathcal{A}}}$ the average optimal connection size (or equivalently, USP size) between cities in $\mathcal{A}$. This amounts to $\mathcal{O}(r_{1}^{2} \tau_{\mathcal{A}} \gamma_{\mathcal{A}} n)$ for storage of USPs and to a total \textbf{preprocessing size} $\bm{\mathcal{O}(r_{2} n^{1.5} + r_{1}^{2} \tau_{\mathcal{A}} \gamma_{\mathcal{A}} n)}$.
		
		\begin{figure}[htb]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_antau_cpsk_size}
		    \captionof{figure}{Changing of $\tau_{\mathcal{A}}$ with increased number of stations in \textit{cpsk} dataset. $\mathcal{A}$ was obtained using algorithm \textit{Locsep} we will talk about later.}
		    \label{plot:antau-cpsk-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_angamma_cpsk_size}
		    \captionof{figure}{Changing of $\gamma_{\mathcal{A}}$ with increased number of stations in \textit{cpsk} dataset. $\mathcal{A}$ was obtained using algorithm \textit{Locsep} we will talk about later.}
		    \label{plot:angamma-cpsk-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[htb]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_antau_gbtr_size}
		    \captionof{figure}{Changing of $\tau_{\mathcal{A}}$ with increased number of stations in \textit{gb-train} dataset. $\mathcal{A}$ was obtained using algorithm \textit{Locsep} we will talk about later.}
		    \label{plot:antau-gbtr-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_angamma_gbtr_size}
		    \captionof{figure}{Changing of $\gamma_{\mathcal{A}}$ with increased number of stations in \textit{gb-train} dataset. $\mathcal{A}$ was obtained using algorithm \textit{Locsep} we will talk about later.}
		    \label{plot:angamma-gbtr-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		On a query from $x$ at time $t$ to $y$, we first perform the \textit{local front search} (see algorithm~\ref{alg:uspora-query}). In this step we explore the neighbourhood of $x$ with a time-dependent Dijkstra's algorithm, which takes on average time $\mathcal{O}(\sqrt{r_{2}n} (\log (\sqrt{r_{2}n}) + \delta))$. We then expand all the USPs between $u$ and $v$ such that $u \in lan(x)$ and $v \in blan(y)$, which takes on average $\mathcal{O}(r_{3} \tau_{\mathcal{A}} \gamma_{\mathcal{A}})$. Finally, from each $v \in blan(y)$ we do a TD Dijkstra, restricted to $bneigh(y)$, leading to time complexity $\mathcal{O}(r_{3}\sqrt{r_{2}n} (\log (\sqrt{r_{2}n}) + \delta))$.
		
		Summing up the three terms we obtain the \textbf{query time} of $\bm{\mathcal{O}(r_{2} r_{3} \sqrt{n} (\log (r_{2}n) + \delta) + r_{3} \tau_{\mathcal{A}} \gamma_{\mathcal{A}})}$.
		
		\textbf{Stretch} of the \textit{USP-OR-A} algorithm is \textbf{1}, as it is exact algorithm. \\
		
		\noindent The resulting bounds do not look very appealing. This is because we wanted to preserve the generality - the concrete bounds will depend on what kind of properties the timetables have and what algorithm for finding the AN set is plugged in. In table~\ref{tab:uspora}, we summarize the parameters of \textit{USP-OR-A} method and provide the bounds for a case when the properties of the timetables correspond to those we have measured in our datasets and when we have an algorithm that finds good AN set.
		
		\begin{table}[h!]
			\centering
			\small
			\begin{tabular}{l|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR-A}} & 
				\cellcolor{oracle-clr} \textbf{guaranteed} & 
				\cellcolor{oracle-clr} \textbf{$\bm{\tau, r_{1}, r_{2}, r_{3}}$ const., $\bm{\gamma \leq \sqrt{n}}$, $\bm{\delta \leq \log n}$} \\
			%data
				\hline
				\cellcolor{oracle-clr} $\bm{prep}$ & $\mathcal{O}(f(n) + (r_{1} + r_{2}) (\delta + \log n) h n^{1.5})$ & $\mathcal{O}(f(n) + h n^{1.5} \log n)$ \\
				\cellcolor{oracle-clr} $\bm{size}$ & $\mathcal{O}(r_{2} n^{1.5} + r_{1}^{2} \tau_{\mathcal{A}} \gamma_{\mathcal{A}} n)$ & $\mathcal{O}(n^{1.5})$ \\
				\cellcolor{oracle-clr} $\bm{qtime}$ & avg. $\mathcal{O}(r_{2} r_{3} \sqrt{n} (\log (r_{2}n) + \delta) + r_{3} \tau_{\mathcal{A}} \gamma_{\mathcal{A}})$ & avg. $\mathcal{O}(\sqrt{n} \log n)$ \\
				\cellcolor{oracle-clr} $\bm{stretch}$ & $1$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:uspora} The summary of the \textit{USP-OR-A} algorithm parameters.}
		\end{table}
		
	\subsubsection{Correctness of \textit{USP-OR-A}}
	
		\noindent Finally, we will proof the correctness of the algorithm, i.e. that it always returns the optimal connection.
		
		\begin{theorem}
			The algorithm \textit{USP-OR-A}~\ref{alg:uspora-prepro}~\ref{alg:uspora-query} always returns the optimal connection.
		\end{theorem}
		
		\begin{proof}
			Let $\mathcal{A}$ be the set of access nodes and consider a query from city $x$ to city $y$ at any time $t$. If $x \in \mathcal{A}$ and $y \in \mathcal{A}$, an optimum is returned due to lemma~\ref{lemma:expandusp} (in such a case, we basically run \textit{USP-OR} algorithm). \\
			
			\noindent In the following we will assume that $\bm{y \not \in neigh(x)}$, which means that the optimal connection goes through some access node $u \in lan(x)$ and $v \in blan(y)$. Note that it may be that $u = v$. \\
			
			\noindent What we would like to prove as a next step is that we reach the back LANs of $y$ (or $y$ itself if it is an access node) at the earliest arrival time. After the \textit{local front search}, we have reached the $x$'s local ANs at times $ea(u) \; \forall u \in lan(x)$. For some local access node this value is the true earliest arrival. Let us denote the set of such local ANs as $lan^{*}(x)$. The crucial thing to realize is, that the optimal connection to any city out of the $x$'s neighbourhood will lead via some $u \in lan^{*}(x)$ (see picture~\ref{fig:usporaproof2}). And because the \textit{inter-AN search} phase finds \textit{optimal} connections between pairs $u \in lan(x)$ and $v \in blan(y)$, it follows that for each $v \in blan(y)$ the $ea(v)$ is the earliest arrival to this city after the \textit{inter-AN search} phase.
			
			\begin{figure}[h!]
				\begin{center}
					\inputTikZ{./tikzpics/usporaproof2}
				\end{center}
				\caption{\label{fig:usporaproof2} On the picture $lan(x) = \{G, H\}$ and $blan(y) = \{G, H, I\}$. In \textbf{thick} we have highlighted the optimal connection. The connection to $H$ is sub-optimal after the \textit{local front search} phase, however the optimal connection to $y$ (and to $H$ and $I$ as well) leads through $lan^{*}(x)$ (some of $x$'s local access nodes to which we have an optimal connection after the \textit{local front search}. Particularly, it goes through $G$).}
			\end{figure}
			
			In the \textit{local back search} we run a TD Dijkstra search from all back LANs of $y$. And since this algorithm is exact and starts from each back LAN as early as possible, we get the optimal connection to $y$. \\
			
			\noindent It remains to show that if $\bm{y \in neigh(x)}$, we also get the optimal connection. In such case, we simply compare the connection that goes via access nodes and the one that was obtained solely within the neighbourhood and output the shorter one. As there are no other options, the proof is complete.
		\end{proof}
	
	\subsubsection{Modifications of \textit{USP-OR-A}}
	
		\noindent Our implementation of the \textit{USP-OR-A} algorithm uses one slight improvement, which we did not mention in its description, since it is more of a optimization technique without any theoretical guarantees on actual improvement of the running time. However, we consider it an interesting idea so we mention it at this place.
		
		\begin{definition}
	        \textbf{USP tree} \\
			Given a pair of cities $x$ and $y$ in a timetable $T$, we will call a USP tree the graph made out of edges of all USPs in $usp_{T}(x, y)$: $\bm{usp^{3}_{T}(x, y)} = (V^{3}, E^{3})$ where $V^{3} = \{v| \; v$ lays on some $p \in usp_{T}(x, y)\}$ and $E^{3} = \{(a, b)| \; (a, b)$ is part of some $p \in usp_{T}(x, y)\}$.
	    \end{definition}
	    
	    \noindent We could take advantage of these USP trees to speed up the \textit{local front search} phase of the algorithm, where we unnecessarily explore the whole neighbourhood when we could just go along the arcs of the USP trees. The picture~\ref{fig:uspora3} depicts this. 
		
		\begin{figure}[h!]
			\begin{center}
				\inputTikZ{./tikzpics/uspora3}
			\end{center}
			\caption{\label{fig:uspora3} Using USP trees (\textbf{thick} non-dashed arcs in \textcolor{purple}{$\bm{neigh_{\mathcal{A}}(x)}$}) to decrease the explored area in \textit{local front search}. A full neighbourhood search is done only when $y \in neigh(x)$.}
		\end{figure}
		
		\noindent The interesting thing about this is the exploitation of both - timetable and its underlying graph. While the neighbourhood of a node is something static, related only to the structure of the UG and generally time-independent, the USP trees reflect to some extent the properties of the timetable (e.g. which ways are frequently serviced and thus provide optimal connections). By intersecting these two things, we get the area that is \textit{worth} to be explored and that is \textit{small} at the same time (provided, of course, that the neighbourhoods are small).	    
	 
\subsection{Selection of access node set}
	
	The challenge in the \textit{USP-OR-A} algorithm comes down to the selection of a good access node set - a $(r_{1}, r_{2}, r_{3})$ AN set with both three parameters as low as possible. However, intuitively (and experimentally verified), decreasing e.g. $r_{1}$ (the AN set size) increases $r_{2}$ (the size of the neighbourhoods). We therefore have to do some compromises.
	
	In the following we first show the problem of choosing an optimal access node set to be NP-hard. We then present our methods for heuristic selection of access nodes and show their performance on real data.
	    
	\subsubsection{Choosing the optimal access node set}

		A question stands - what is an optimal access node set?	To keep the query time as low as possible, we need to avoid large neighbourhood sizes, because that would mean spending too much time doing local searches. A pretty good upper bound for neighbourhood sizes seems to be $\sqrt{n}$ (i.e. $r_{1} = 1$) - the idea is that in such case the local searches cannot possibly last longer then $\mathcal{O}(n)$ while the \textit{inter-AN search} is linear in the size of the connection and can also be at most $\mathcal{O}(n)$. In practice, both of these steps will be faster because the neighbourhoods are sparse and because the connections are on average much shorter then $n$. However, it gives an idea of why $\sqrt{n}$ should be considered for a target neighbourhood size.
		
		Therefore, the question stands: What is the smallest set of ANs, such that the neighbourhood sizes are all under $\sqrt{n}$? More formally, for a timetable $T$, the task is to minimize $|\mathcal{A}|$ where $\mathcal{A} \subseteq ct_{T}$ and $\forall x \in ct_{T} \setminus \mathcal{A}: |neigh_{\mathcal{A}}(x)| \leq \sqrt{n}$. We will call this the \textbf{problem of the optimal access node set} and in what follows we will show that it is NP-complete.
		
		\begin{theorem}
			The problem of the optimal access node set is NP-complete
		\end{theorem}
		
		\begin{proof}
			We will make a reduction of the \textit{min-set cover} problem (a NP-complete problem) to the problem of optimal AN set. \\
			
			\noindent Consider an instance of the min-set cover problem:
			\begin{itemize}
				\item A universe $U = \{1, 2, ..., m\}$
				\item $k$ subsets of $U$: $S_{i} \subseteq U \; i = \{1, 2, ..., k\}$ whose union is $U$: $\bigcup\limits_{1 \leq i \leq k} S_{i} = U$
			\end{itemize}
			\hspace*{\fill}
			
			\noindent Denote $\mathcal{S} = \{S_{i}| \; 1 \leq i \leq k\}$. The task is to choose the smallest subset $\mathcal{S}^{*}$ of $\mathcal{S}$ that still covers the universe ($\bigcup\limits_{S_{i} \in \mathcal{S}^{*}} S_{i} = U$). We will now do a simple conversion (in polynomial time) of the instance of min-set cover to the instance of the optimal AN set problem (which is represented by the underlying graph of $T$).
			
			 For each $j \in U$, we will make a complete graph of $\beta_{j}$ vertices (the value of $\beta_{j}$ will be discussed later) named $m_{j}$ and for each set $S_{i}$ we make a vertex $s_{i}$ and vertex $s_{i}'$. We now connect all vertices of $m_{j}$ to $s_{i} \iff j \in S_{i}$. Finally, for we connect $s_{i}$ to $s_{i}'$, $1 \leq i \leq k$. \\
			 
			\noindent \textbf{Example}. Let $m = 10$ (thus $U = \{1, 2, ..., 10\}$) and $k = 13$:
			\begin{itemize}
				\item $S_{1} = \{1, 3, 10\}$
			 	\item $S_{2} = \{1, 2\}$
			 	\item ...
			 	\item $S_{13} = \{2, 3, 10\}$
			\end{itemize}
			\hspace*{\fill}
			 
			\noindent For this instance of min set-cover, we construct the graph depicted on picture~\ref{fig:reduction}.
			 
			\begin{figure}[h!]
				\begin{center}
					\inputTikZ{./tikzpics/reduction}
				\end{center}
				\caption{\label{fig:reduction} The principle of the reduction. In $m_{i}$, there are actually complete graphs of $\beta_{i}$ vertices (as shown for $m_{1}$). \textbf{Thick} arcs represent arcs from all the vertices of respective $m_{i}$. The $s_{i}$ vertices are connected to their $s_{i}'$ versions. If e.g. $s_{1}$ is selected as an access node, $s_{1}'$ is no longer part of any neighbourhood.}
			\end{figure}
			
			\noindent Now we would like to clarify the sizes of $m_{i}$. Define $\alpha_{i}$ to be the number of sets $S_{j}$ that contain $i$: $\alpha_{i} = |\{S_{j} \in \mathcal{S}| \; i \in S_{j}\}|$ and assume the constructed graph has $n$ vertices. We want the $\beta_{i}$ to satisfy $\beta_{i} \geq 2$ and $\beta_{i} + 2\alpha_{i} - 1 \leq \sqrt{n}$ but $\beta_{i} + 2\alpha_{i} > \sqrt{n}$. The last two inequalities would mean that if at least one $s_{j}$ connected to $m_{i}$ is chosen as an access node, the neighbourhood for nodes in $m_{i}$ will be still $\leq$ $\sqrt{n}$, but if none of them is chosen, the neighbourhood will be just over $\sqrt{n}$. For now we will assume that we have constructed the graph in such a way that all $\beta_{i}$ satisfy the mentioned inequalities. We will return to construction of the graph at the end.
			
			Now consider an optimal AN set which contains a vertex from within some $m_{i}$. If this is the case, \textbf{either} some $s_{j}$ to which $m_{i}$ is connected is selected as AN, \textbf{or} \textit{all} vertices from $m_{i}$ are access nodes \textbf{or} the neighbourhood is too large. Keep in mind that the local access nodes are also part of neighbourhoods, so unless we select for AN some of the $s_{j}$ that $m_{i}$ is connected to, the neighbourhood of any non-access node in $m_{i}$ will be too large. As there are at least two nodes in every $m_{i}$, it is more efficient to select some $s_{j}$ rather then select all nodes in $m_{i}$. Thus when it comes to selecting ANs \textit{it is worth to consider only vertices $s_{j}$}.
			
			From this point on, it is easy to see that it is optimal to select those $s_{j}$ that correspond to the optimal solution of min-set cover. The reason is that each of the $m_{i}$ will be connected to at least one access node $s_{j}$ and will thus have neighbourhood size $\leq \sqrt{n}$, while the number of selected access nodes will be optimal. \\
			
			\noindent It remains to show how to choose values $\beta_{i}$. Due to the condition $\beta_{i} \leq \sqrt{n} - 2\alpha_{i} + 1$ we need to have sufficiently big $n$ to fulfil $\beta_{i} \geq 1$. We will accomplish this by adding dummy isolated vertices to the graph. Define function \textit{nextSquare($x$)} to output the smallest $y^{2} > x$ where $y$ is a natural number. We then compute $w = (max\{2\alpha_{i}\} + 2)^{2}$ and select the starting value of $n$ to be $n' =$ \textit{nextSquare($max\{w - 1, \; \sqrt{2k + m}\}$)}. We create the $s_{j}$ and $s_{j}'$ vertices and complete graphs $m_{i}$ containing so far only one vertex each. We connect everything according to the rules stated earlier in this proof and we create dummy vertices up to the capacity defined by $n$. Now we repeat the following:
			
			\begin{itemize}
				\item We compute $\sqrt{n}$ which is a natural number
				\item For $i$ from $1$ to $m$ we add vertices to $m_{i}$ till it does not contain $\sqrt{n} - 2\alpha_{i} + 1$ vertices. For each added vertex we delete one dummy vertex.
				\item If we run out of dummy vertices, $n =$ \textit{nextSquare($n$)}
				\item Break out of the loop if $|m_{i}| = \sqrt{n} - 2\alpha_{i} + 1 \; \forall i$
			\end{itemize}
			\hspace*{\fill}
			
			\noindent With each iteration of this little algorithm we will be forced to add one more vertex to all $m_{i}$ (since $\sqrt{n}$ increased by one), a so called \textit{inefficient increase}. At the beginning, we need to make at most $m\sqrt{n'}$ efficient increases to meet the breaking condition. And since $m$ is constant and the capacity of new dummy vertices increases linearly, after $t$ steps we create $\mathcal{O}(t^{2})$ dummy vertices that may be used for efficient increases. Therefore, the algorithm will stop after $\mathcal{O}(\sqrt{mn'})$ steps.
		\end{proof}
	
	\subsubsection{Choosing ANs based on node properties}
	
		In the previous sub-subsection, we have shown the problem of choosing the optimal AN set to be NP-hard. In this sub-subsection we perform a simple experiment of choosing for the access nodes the cities that seem to be the most important. More specifically, in the optimistic underlying graph (see section~\ref{sec:prel}) $ug_{T}^{opt}$ we were looking for cities with:
		\begin{enumerate}
			\item High \textbf{degree}. We consider the sum of in-degree and out-degree~\footnote{In-degree is the number of arcs going towards to node and out-degree the number of outgoing arcs.} of the respective node $x$: $\bm{deg(x)} = deg_{in}(x) + deg_{out}(x)$.
			\item High \textbf{betweenness centrality} (BC). Betweenness centrality for a node $v$ is defined as 
			
			$$g(v) = \sum_{s \neq v \neq t} \frac{\displaystyle \sigma_{st}(v)}{\displaystyle \sigma_{st}}$$
			
			where $\sigma_{st}(v)$ is the number of shortest paths from $s$ to $t$ passing through $v$ and $\sigma_{st}$ is the total number of shortest paths from $s$ to $t$~\cite{centrality01}. We then scale the values to the range $<0, 1>$ to obtain for each city $x$ its scaled betweenness centrality $\bm{bc(x)}$.
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent We will denote by $\mathcal{A}_{deg}(k)$ the set of $k$ cities with highest $deg(x)$ value. We were interested in the smallest $k$ such that:
		\begin{enumerate}
			\item $\mathcal{A}_{deg}(k)$ is $(r_{1}, r_{2}, r_{3})$ AN set with $r_{2} \leq 1$ (the average square of neighbourhoods is $\leq \sqrt{n}$). Denote such $r_{1}$ as $\bm{r_{deg}^{avg}}$~\footnote{Intuitively - $r_{deg}^{avg}$ is the smallest $r_{1}$ such that $r_{1}\sqrt{n}$ highest-degree nodes selected as ANs are enough to satisfy that the average square of neighbourhoods is $\leq \sqrt{n}$.}.
			\item $\mathcal{A}_{deg}(k)$ is $(r_{1}, r_{2}, r_{3})$ AN set where $\forall x \in ct_{T}$: $|neigh_{\mathcal{A}_{deg}(k)}(x)| \leq \frac{3\sqrt{n}}{2}$ and $|bneigh_{\mathcal{A}_{deg}(k)}(x)| \leq \frac{3\sqrt{n}}{2}$ (all neighbourhoods are large at most $\frac{3\sqrt{n}}{2}$). Denote such $r_{1}$ as $\bm{r_{deg}^{max}}$.
		\end{enumerate}		 
		\hspace*{\fill}
		
		\noindent We define similarly $\bm{r_{bc}^{avg}}$ and $\bm{r_{bc}^{max}}$. The resulting values for datasets \textit{sncf} and \textit{cpru} could be seen on plots~\ref{plot:hbcdeg-size}.
		
		\begin{figure}[htb]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_hbcdeg_sncf_size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_hbcdeg_cpsk_size}
	    \end{minipage}
	    }
	    \caption{\label{plot:hbcdeg-size} Necessary sizes of access node sets ($|\mathcal{A}| = r_{1} \sqrt{n}$) based on high-degree/high-BC cities. Datasets \textit{sncf} (left) and \textit{cpsk} (right). Notice the occasional ``roller coaster'' bumps (especially on the left plot) - an explanation of this phenomena is that in the immediately smaller sub-timetable we have erased just the high-degree node that proved to be a good access node, and which now must be substituted by many other access nodes.}
		\end{figure}
		
	\subsubsection{Choosing ANs heuristically - the \textit{Locsep} algorithm}
	
		Clearly, selecting the cities for access nodes solely by high degree or BC value is not the best way. Probably the few nodes with highest degrees and BC will indeed be part of the AN set, as they are intuitively some sort of central hubs without which the network would not work. However, after we select the these most important nodes to the AN set, we need some better measure of node's importance, or suitability to be an access node. In the following we present a simple heuristic approach run on underlying graph $ug_{T}$ of given timetable $T$ that evaluates its vertices based on how good local separators they are. 
		
		The algorithm that we call \textit{Locsep} (as it looks for good local separators) will work in iterations, each of them resulting in a selection of the city with the highest score to the access node set $\mathcal{A}$~\footnote{Actually, in our implementation, we allow an occasional deselection of an already selected node with the \textit{lowest} score, to avoid having in the resulting set cities that had high score when selected but were not very useful access nodes at the end.}. We continue to select access nodes until we meet the following stopping criterion: $\mathcal{A}$ is $(r_{1}, r_{2}, r_{3})$ AN set with $r_{2} \leq 1$ (the average square of neighbourhoods is $\leq \sqrt{n}$)~\footnote{In our implementation, we perform some further adjustments of the resulting set, such as removing unnecessary access nodes and optimising the $r_{3}$ value.}. We will denote $\bm{r_{ls}} = r_{1}$ of the resulting access node set. 
		
		The important thing that remains to be shown is how do we compute the score for a particular city. The following text explains this. \\
		
		\noindent In each iteration, we first compute the neighbourhoods and back neighbourhoods (given the current access node set $\mathcal{A}$) for each city. We need this to evaluate the stopping criteria, but the information is also used in the computation of the \textbf{potential} (the score) of the cities. \\
		
		\noindent For a city $x$, we compute its potential $\bm{p_{x}}$ in the following way: we explore an area $\bm{A_{x}}$ of $\sqrt{n}$ nearest cities around $x$, ignoring branches of the search that start with an access node ($x$ is an exception to this, since we start the search from it. However $x \not \in A_{x}$ holds). We do this exploration in an underlying graph with no orientation and no weights. Next we get the front and back neighbourhoods of $x$ within $A_{x}$ ($\bm{fn(x)} = neigh(x) \cap A_{x}$, $\bm{bn(x)} = bneigh(x) \cap A_{x}$).
		
		For a set of access nodes $\mathcal{A}$, let us call a path $p$ in $ug_{T}$ \textbf{access-free} if it does not contain a node from $\mathcal{A}$. Now as long as $x$ is not in $\mathcal{A}$, we have a guarantee that for every pair $u \in bn(x)$ and $v \in fn(x)$ there is an access-free path from $u$ to $v$ within $A_{x}$. Our interest is how this will change after the selection of $x$.
				
		Consider now a node $y \in bn(x)$. We will call $\bm{sur(y)} = \max\{0, |neigh(y)| - \sqrt{n}\}$ the \textbf{surplus} of $y$'s neighbourhood, i.e., by how much we wish to reduce it so that it is $\leq \sqrt{n}$. If the surplus is zero, $y$ will not add anything to the $x$'s potential. Otherwise, we run a restricted (to $A_{x}$) search from $y$ during which we explore $j$ vertices in $fn(x)$. We increase the potential of $x$ by $\min\{sur(y), |fn(x) - j|\}$ - i.e. by how much we can decrease the surplus of $y$'s neighbourhood. We do the same for all $y \in bn(x)$ and a similar thing for all $y \in fn(x)$ (we use $\overleftarrow{ug_{T}}$ instead of $ug_{T}$, $bneigh(y)$ instead of $neigh(y)$ etc...). For an illustration of potential computing, see picture~\ref{fig:locsep}. \\
		
		\begin{figure}[h!]
			\begin{center}
				\inputTikZ{./tikzpics/locsep}
			\end{center}
			\caption{\label{fig:locsep} The principle of computing potentials in \textit{Locsep} algorithm. We explored an area of $\sqrt{n}$ nearest cities (in terms of hops) around $x$. Access nodes (like $z$) and cities behind them are ignored. Little \textcolor{purple}{squares} are nodes from $fn(x)$ and \textcolor{cyan}{diamonds} are part of $bn(x)$. From $y$ we run a forward search (the \textbf{thick} arcs). Nodes from the $fn(x)$ that were not explored in this search can only be reached via $x$ itself. Such nodes contribute to $x$'s potential assuming $y$ has large neighbourhood size.}
		\end{figure}

		\noindent Finally, we simply get the city $x \not \in \mathcal{A}$ with the highest potential and select it as an access node. We check the stopping criterion and in case it is not satisfied yet, we move on to next iteration. However, note that when a new node $x'$ is selected to $\mathcal{A}$, we do not have to re-compute neighbourhoods and potentials of all cities - it is only necessary for those cities that could reach/be reached access-free from $x'$ (i.e. nodes from $neigh_{\mathcal{A}}(x') \cup bneigh_{\mathcal{A}}(x')$). Algorithm~\ref{alg:locsep} provides a high-level overview of the Locsep method. \\
		
		\color{algcolor}
		\begin{algorithm}[H]
			\color{inalgcolor}
			\caption{\textit{Locsep}}
			\label{alg:locsep}
			\textbf{Input} 
			\begin{itemize}
				\item $ug_{T}$
			\end{itemize}
			\textbf{Algorithm}
			\begin{algorithmic}
				\STATE $\mathcal{A} = \emptyset$
				\STATE $ct' = ct_{T}$
				\WHILE{$r_{2} > 1$}
					\STATE $\forall x \in ct'$: compute $neigh_{\mathcal{A}}(x)$, $bneigh_{\mathcal{A}}(x)$
					\STATE $\forall x \in ct'$: compute $p_{x}$
					\STATE $x' = argmax_{x \not \in \mathcal{A}} \{p_{x}\}$
					\STATE $\mathcal{A} = \mathcal{A} \cup \{x'\}$
					\STATE $ct' = neigh_{\mathcal{A}}(x') \cup bneigh_{\mathcal{A}}(x')$
				\ENDWHILE
				\STATE Remove unnecessary ANs
				\STATE Optimise $r_{3}$
			\end{algorithmic}
			\textbf{Output}
			\begin{itemize}
				\item AN set $\mathcal{A}$, such that $|\mathcal{A}| = \sqrt{n} r_{locsep}$
			\end{itemize}
		\end{algorithm}
		\color{black}
		
		\noindent Now we would like to estimate the \textbf{time complexity} of Locsep algorithm. As mentioned, one iteration consists of three parts:
		\begin{enumerate}
			\item Computing neighbourhoods. Unfortunately, at the beginning when $\mathcal{A} = \emptyset$, the neighbourhood sizes may be as large as $\mathcal{O}(n)$. Therefore, we may bound the complexity of this phase only as $\mathcal{O}(nm) = \mathcal{O}(\delta n^{2})$.
			\item Computing potentials. For a city $x$ we explore area of the size $\sqrt{n}$ and from each node in that area we do a restricted search. Therefore the total complexity of this step is $\mathcal{O}(n \cdot \sqrt{n} \cdot \delta \sqrt{n}) = \mathcal{O}(\delta n^{2})$.
			\item Selecting node with the highest potential. This can be done in $\mathcal{O}(n)$.
		\end{enumerate}
		\hspace*{\fill}
		
		\noindent Adding up the individual terms, we get the complexity of one iteration to be at most $\mathcal{O}(\delta n^{2})$. As we aim for the resulting access node set of size $\mathcal{O}(\sqrt{n})$, we would get the total running time of $\bm{\mathcal{O}(\delta n^{2.5})}$. However, we remind that the algorithm is only a heuristics with no guarantees on the resulting access node set size~\footnote{The algorithm basically selects access nodes on a greedy basis. However, even that is done only heuristically, using only local scope to reduce the time complexity.}.
		
		The resulting running time is still quite impractical for bigger timetables. For example, the computation on the dataset \textit{sncf} took more than an hour. This is due to the initial iterations, during which average neighbourhood is still very large (spanning almost the whole graph) and thus in the first two phases we have to do a lot of re-computations. We therefore embrace a simple trick: we do not start with $\mathcal{A} = \emptyset$ but with some access nodes already selected based on high degree. We chose to start with $\frac{\sqrt{n}}{2}$ nodes with the highest degree ($\mathcal{A}_{deg}(\frac{\sqrt{n}}{2})$) - enough to speed-up the computation but not influencing the resulting AN set too much. 
		
		The access node sets chosen with the \textit{Locsep} algorithm were much smaller then those selected by the previous approaches and with the increasing number of stations, the $r_{locsep}^{avg}$ value was found to increaser only slightly, as could be seen from plots~\ref{plot:locsep-size}. The average number of local access nodes for each city was also found to be very small and increasing only very little with increasing $n$. \\
		
		\begin{figure}[h!]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_locsep_sncf_size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_locsep_cpsk_size}
	    \end{minipage}
	    }
	    \caption{\label{plot:locsep-size} The necessary size of $\mathcal{A}$ when selecting ANs based on degree, BC or with \textit{Locsep} algorithm. Datasets \textit{sncf} (left) and \textit{cpsk} (right). An ideal situation would be a constant or non-increasing function, to which \textit{Locsep} comes closest.}
		\end{figure}				
		
		\noindent To sum up, in \textit{all} of our datasets~\footnote{Except \textit{air01}, which is a special type of timetable.}, each scaled to \textit{various} sizes, we were always able to find $(r_{1}, r_{2}, r_{3})$ access node set $\mathcal{A}$ with the \textit{Locsep} algorithm, such that:
		\begin{itemize}
			\item $r_{1} \leq todo$
			\item $r_{2} \leq todo$
			\item $r_{3} \leq todo$
			\item $\mathcal{A}$ can be found in $\mathcal{O}(\delta n^{2.5})$
		\end{itemize}
		\hspace*{\fill}
		
		\noindent Therefore, when we use \textit{USP-OR-A} together with \textit{Locsep} on our timetables, we achieve parameters as described in table~\ref{tab:usporalocsep}.
		
		\begin{table}[h!]
			\centering
			\begin{tabular}{l|c|c|c|c}
			%legend
				\cellcolor{oracle-clr} \textit{\textbf{USP-OR-A + Locsep}} & \cellcolor{oracle-clr} $\bm{prep}$ & \cellcolor{oracle-clr} $\bm{size}$ & \cellcolor{oracle-clr} $\bm{qtime}$ & \cellcolor{oracle-clr} $\bm{stretch}$ \\
			%data
				\hline
				\cellcolor{oracle-clr} \textbf{Our timetables} & $\mathcal{O}(\delta n^{2.5})$ & $\mathcal{O}(n^{1.5})$ & avg. $\mathcal{O}(\sqrt{n} \log n)$ & $1$ \\
			\end{tabular}
			\caption{\label{tab:usporalocsep} Parameters for \textit{USP-OR-A} with \textit{Locsep}.}
		\end{table}
	
\subsection{Performance and comparisons}

	\noindent In this subsection we give the results of the performance of our algorithms on our datasets. We focus on query time and space complexity of the preprocessed oracles. We have already introduced the speed-up as the ratio of average query time for the TD Dijkstra and the average query time for the given algorithm. We will have a similar measure for the size of the preprocessed data, which we compare against the amount of data needed to represent the actual timetable itself.
	
	\begin{definition}
		\textbf{Size-up ($\bm{szp(m)}$)}\\
		A size-up of an oracle based method $m$ is the ratio $\frac{\displaystyle size(TD)}{\displaystyle size(m)}$ where $size(TD)$ is the size of the memory necessary to store the time-dependent graph.
	\end{definition}

	\subsubsection{Performance of \textit{USP-OR}}
		
		Query time-wise, \textit{USP-OR} outperforms time-dependent Dijkstra's algorithm almost 80 times (on the subset of \textit{sncf-ter} dataset). However, this was at the cost of high space consumption of the method, in some cases requiring almost 400 times more memory then necessary for storage of the time-dependent graph. Therefore, we were not even able to preprocess the method for some of our bigger datasets. Table~\ref{tab:uspor-speedup} gives a good overview of achieved speed-ups and size-ups.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru}* & 700 & 14.5 & 396.7 \\
				\textit{cpza}* & 700 & 14.3 & 265.1 \\
				\textit{montr} & 217 & 8.8 & 61.1\\
				\textit{sncf}* & 1000 & 64.8 & 106.2 \\
				\textit{sncf-inter} & 366 & 27.0 & 30.3 \\
				\textit{sncf-ter}* & 1000 & 78.3 & 87.4 \\
				\textit{zsr} (daily) & 233 & 19.3 & 60.8 \\
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR} algorithm for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:uspor-speedup}
		\end{table}
	
		\noindent In both timetables from \textit{cp.sk} we obtained quite similar results. The query time of \textit{USP-OR} mildly rises with increasing $n$. This is due to two (not surprising) facts: 
		\begin{itemize}
			\item The USP coefficient gets slightly bigger with increasing $n$
			\item The OC radius increases too with increasing $n$
		\end{itemize}
		\hspace{\fill}
		
		\noindent The speed-up was up to 15, however, at the cost of very high space complexity, which made it possible to try out only timetables of the size up to 700. With the \textit{montr} dataset we got similar results, but on a smaller scale.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_cpru_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{cpru}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-cpru-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-cpza-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_montr_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{montr}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-montr-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspors-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent In the datasets from SNCF, an interesting thing was that the the query-time actually decreased with increased size. This was due to the average USP coefficient getting smaller in bigger datasets while OC radius not increasing too much. We measured here the speed-ups of up to 80 for \textit{sncf-ter}, with smaller size-ups then in case of \textit{cp.sk} timetables.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_sncfinter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf-inter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncfinter-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_sncfter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf-ter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncfter-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspor_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspor-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspors-sncf-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent On the \textit{zsr} dataset we measured how increased time range influences the query time. You may see that for both algorithms the query time almost stops increasing at some point - this is because (informally) adding time range no longer brings along new optimal connections (or underlying shortest paths in case of \textit{USP-OR}).
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspor_zsr_trange}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR} algorithm compared to TD Dijkstra on the \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspor-zsr-trange}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspors_zsr_trange}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR} vs. size of TD graph on \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspors-zsr-trange} 
	    \end{minipage}
	    }
		\end{figure}

	\subsubsection{\textit{USP-OR-A} with \textit{Locsep}}
	
		\noindent With \textit{USP-OR-A}, the speed-ups were no longer so high as in case of \textit{USP-OR-A}, but neither were the size-ups, so we could fully try out all of our datasets. The maximum speed-up was achieved in \textit{sncf-ter}, where the \textit{USP-OR-A} outperformed \textit{TD Dijkstra} almost 7 times. In our datasets, the preprocessed oracle of \textit{USP-OR-A} did not need more than 3 times the size of the TD graph. Table~\ref{tab:uspora-speedup} provides an overview of achieved speed-ups and size-ups.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru} & 871 & 1.8 & 2.97 \\
				\textit{cpza} & 1108 & 1.9 & 2.52 \\
				\textit{montr} & 217 & 1.6 & 1.14 \\
				\textit{sncf} & 2646 & 6.3 & 3.0 \\
				\textit{sncf-inter} & 366 & 3.9 & 1.59 \\
				\textit{sncf-ter} & 2637 & 6.9 & 2.43 \\
				\textit{zsr} (daily) & 233 & 2.5 & 1.99 \\	
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR-A} with \textit{Locsep} for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:uspora-speedup}
		\end{table}
	
		\noindent The bus timetables proved to be a bigger challenge for \textit{USP-OR-A}, achieving milder speed-ups and requiring more memory then railways timetables. However, bigger timetables would be necessary to obtain more relevant results.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_cpru_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{cpru}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-cpru-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-cpza-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_montr_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{montr}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-montr-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{Locsep} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporas-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent In our biggest datasets, we achieved the best speed-ups while the size-up still stayed relatively small (though here we better see its tendency to increase as $n^{1.5}$). It would be interesting to try out even bigger datasets as the speed-up was gradually increasing with increasing $n$.
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_sncfinter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{sncf-inter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncfinter-size}  
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_sncfter_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{sncf-ter}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncfter-size} 
	    \end{minipage}
	    }
		\end{figure}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_uspora_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:uspora-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{Locsep} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}   
		    \label{plot:usporas-sncf-size}
	    \end{minipage}
	    }
		\end{figure}
		
		\noindent Finally, on the \textit{zsr} timetable, we see two things:
		\begin{itemize}
			\item The space-complexity of \textit{USP-OR-A} is left pretty much unaffected with increased time range.
			\item The speed-up decreases (since with increased time range, there are generally more USPs between pairs of cities which we have to try out during the query)
		\end{itemize}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_uspora_zsr_trange}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep} compared to TD Dijkstra on the \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:uspora-zsr-trange}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporas_zsr_trange}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{Locsep} vs. size of TD graph on \textit{\textbf{zsr}} dataset. \textbf{Changing $\bm{r}$}.}
		    \label{plot:usporas-zsr-trange}
	    \end{minipage}
	    }
		\end{figure}
	
	\subsubsection{\textit{USP-OR-A} with \textit{Locsep Max}}
	
		\noindent We also tried out \textit{USP-OR-A} with \textit{Locsep Max} to see if the difference in the stopping criterion of \textit{Locsep} would influence the query times. It did help, but the difference in the performance is minimal, therefore we list only the table summarizing the speed-ups and size-ups (\ref{tab:usporam-speedup}) and the details for datasets \textit{cpza} and \textit{sncf}.
	
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c}
			%legend
	            \rowcolor{tablehead}
	            \textbf{Name} & $\bm{n}$ & $\bm{spd}$ & $\bm{szp}$ \\
			%data
				\hline
				\textit{cpru} & 871 & 2.1 & 4.5 \\
				\textit{cpza} & 1108 & 2.1 & 3.1 \\
				\textit{montr} & 217 & 2.1 & 1.9 \\
				\textit{sncf} & 2646 & 6.6 & 3.0 \\
				\textit{sncf-inter} & 366 & 4.3 & 1.6 \\
				\textit{sncf-ter} & 2637 & 7.1 & 2.43 \\
				\textit{zsr} (daily) & 233 & 2.3 & 1.94 \\	
			\end{tabular}
			\captionof{table}{Speed-ups and size-ups of the \textit{USP-OR-A} with \textit{Locsep Max} for the whole timetables (for those marked with asterisk we took only a subset of $n$ stations, as we were limited by the space).}
			\label{tab:usporam-speedup}
		\end{table}
		
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth}  
		    \centering
		    \inputTikZ{./tikzpics/plot_usporam_cpza_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep Max} compared to TD Dijkstra on the \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporam-cpza-size}
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporams_cpza_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{Locsep Max} vs. size of TD graph on \textit{\textbf{cpza}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporams-cpza-size}   
	    \end{minipage}
	    }
		\end{figure}
	
		\begin{figure}[H]
		\centering
		\makebox[0pt][c]{
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporam_sncf_size}
		    \captionof{figure}{\textbf{Query time} of \textit{USP-OR-A} with \textit{Locsep Max} compared to TD Dijkstra on the \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}
		    \label{plot:usporam-sncf-size}   
	    \end{minipage}
		\hspace{1cm}
	    \begin{minipage}{0.45\textwidth} 
	    	\centering
		    \inputTikZ{./tikzpics/plot_usporams_sncf_size}
		    \captionof{figure}{\textbf{Size} (in MB) of the oracle for \textit{USP-OR-A} with \textit{Locsep Max} vs. size of TD graph on \textit{\textbf{sncf}} dataset. \textbf{Changing $\bm{n}$}.}   
		    \label{plot:usporams-sncf-size}
	    \end{minipage}
	    }
		\end{figure}
